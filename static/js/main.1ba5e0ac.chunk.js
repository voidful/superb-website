(this["webpackJsonpsuperb-website"]=this["webpackJsonpsuperb-website"]||[]).push([[0],{376:function(e,t,n){},377:function(e,t,n){},780:function(e,t,n){"use strict";n.r(t);var a=n(0),i=n.n(a),r=n(30),s=n.n(r),o=(n(376),n(9)),c=(n(377),n(41)),l=n(53),d=n(836),h=n(841),u=n(349),p=n(869),m=n(140),b=n(838),g=n(40),j=n(783),f=n(10),O=n(7),w=n(209),x=n(1);function v(e){var t=Object(w.a)(),n=e.anchorKey,a=Object(O.a)(e,["anchorKey"]);return Object(x.jsxs)(i.a.Fragment,{children:[Object(x.jsx)(p.a,{id:n,position:"relative",top:t.spacing(-4),visibility:"hidden"}),Object(x.jsx)(p.a,Object(f.a)({},a))]})}function S(e){var t=Object(w.a)();return Object(x.jsx)(v,Object(f.a)({margin:t.spacing(4,"auto",8)},e))}function y(e){var t=Object(w.a)();return Object(x.jsx)(v,Object(f.a)({margin:t.spacing(4,"auto",6)},e))}function k(e){var t=Object(w.a)();return Object(x.jsx)(v,Object(f.a)({margin:t.spacing(4,"auto",4)},e))}var _=n(38),T=n(837),A=n(839),R=n(32),P=Object(d.a)((function(e){return{}}));function E(e){var t=e.link,n=e.children,a=t?R.a:p.a,i=Object(c.g)();Object(g.a)(),P();return Object(x.jsx)(p.a,{component:"span",fontWeight:i.pathname.includes(t)?"bold":"inherit",children:(t||"").includes("http")?Object(x.jsx)("a",{className:"unlink",href:t||"",target:"_blank",children:n}):Object(x.jsx)(a,{className:"unlink",to:t||"",children:n})})}var C=Object(d.a)((function(e){return{descriptionButton:{display:"inline-block",margin:e.spacing(1)},pseudoOutlinedPrimaryButton:{backgroundColor:"transparent",border:"1px solid ".concat(Object(_.b)(e.palette.primary.main,.5)),borderRadius:e.shape.borderRadius,display:"inline-block"},innerButton:{paddingLeft:e.spacing(2),paddingRight:e.spacing(2)}}}));function B(e){var t=e.name,n=e.link,a=C();return Object(x.jsx)(E,{link:n,children:Object(x.jsx)(T.a,{size:"small",variant:"outlined",className:a.descriptionButton,children:t})})}function N(e){var t=e.buttons,n=void 0===t?[{name:"rules",link:"/submit#rules"},{name:"submit",link:"/submit#submit"}]:t,a=C();return Object(x.jsx)("div",{className:a.pseudoOutlinedPrimaryButton,children:Object(x.jsx)(b.a,{container:!0,direction:"row",justify:"center",alignItems:"center",spacing:0,children:n.map((function(e,t){var r=e.name,s=e.link;return Object(x.jsxs)(i.a.Fragment,{children:[Object(x.jsx)(b.a,{item:!0,children:Object(x.jsx)(E,{link:s,children:Object(x.jsx)(T.a,{disabled:!s,color:"primary",className:a.innerButton,children:r})})}),t<n.length-1&&Object(x.jsx)(b.a,{item:!0,children:Object(x.jsx)(p.a,{height:28,children:Object(x.jsx)(A.a,{orientation:"vertical"})})})]})}))})})}function L(e){return e.charAt(0).toUpperCase()+e.slice(1)}function $(e){return Object(x.jsx)(p.a,{component:"span",fontWeight:"bold",fontStyle:"italic",children:e.children})}function I(e){return"number"==typeof e&&!isNaN(e)}function D(e,t,n,a){var i=e.original[n],r=t.original[n],s=I(i),o=I(r);return!s&&o?a?-1:1:s&&!o?a?1:-1:s||o?i>r?1:-1:a?e.original.submitName<t.original.submitName?1:-1:e.original.submitName<t.original.submitName?-1:1}var z=n(304),H=n.n(z),F=n(305),U=n.n(F),W=n(306),M=n.n(W),q=n(202),V=n(840),Y=n(203),Q=n(204),J=n(205),K=n(120),G=n.n(K),X={palette:{primary:{main:q.a[100]},text:{primary:V.a[600],secondary:q.a[600]}}},Z=G()(X,{palette:{primary:{main:{$set:Y.a[400]}}}}),ee=G()(X,{palette:{primary:{main:{$set:Q.a[400]}}}}),te=G()(X,{palette:{primary:{main:{$set:J.a[400]}}}}),ne=G()(X,{palette:{primary:{main:{$set:V.a[600]}}}}),ae="https://forms.gle/sVMWx9FHjL4DvK3K8",ie=[{name:"recognition",description:"recognition description",tasks:[{name:"PR",description:"            Phoneme Recognition, PR transcribes an utterance into the smallest content units.            We include alignment modeling in the PR task to avoid the potential inaccurate forced alignment.            LibriSpeech train-clean-100/dev-clean/test-clean subsets are adopted in SUPERB for training/validation/testing.            Phoneme transcriptions are obtained from the LibriSpeech official g2p-model-5 and the conversion script in Kaldi librispeech s5 recipe.            The evaluation metric is phone error rate (PER).          "},{name:"ASR",description:"            Automatic Speech Recognition, ASR transcribes utterances into words.            While PR analyzes the improvement in modeling phonetics, ASR reflects the significance of the improvement in a real-world scenario.            LibriSpeech train-clean-100/devclean/test-clean subsets are used for training/validation/testing.            The evaluation metric is word error rate (WER).          "}]},{name:"detection",description:"detection description",tasks:[{name:"KS",description:"            Keyword Spotting, KS detects preregistered keywords by classifying utterances into a predefined set of words.            The task is usually performed on-device for the fast response time.            Thus, accuracy, model size, and inference time are all crucial.            We choose the widely used Speech Commands dataset v1.0 for the task.            The dataset consists of ten classes of keywords, a class for silence, and an unknown class to include the false positive.            The evaluation metric is accuracy (ACC)          "},{name:"QbE",description:"            Query by Example Spoken Term Detection, QbE detects a spoken term (query) in an audio database (documents) by             binary discriminating a given pair of query and document into a match or not.            The English subset in QUESST 2014 challenge is adopted since we focus on investigating English as the first step.            The evaluation metric is maximum term weighted value (MTWV) which balances misses and false alarms.            In the SUPERB Challenge, the average between Mean Average Precision (MAP) and Equal Error Rate (ERR) is used as the metric on the hidden-set          "}]},{name:"semantics",description:"semantics description",tasks:[{name:"IC",description:"            Intent Classification, IC classifies utterances into predefined classes to determine the intent of speakers.            We use the Fluent Speech Commands dataset, where each utterance is tagged with three intent labels: action, object, and location.            The evaluation metric is accuracy (ACC).          "},{name:"SF",description:"            Slot Filling, SF predicts a sequence of semantic slot-types from an utterance,             like a slot-type FromLocation for a spoken word Taipei, which is known as a slot-value.            Both slot-types and slot-values are essential for an SLU system to function.            The evaluation metrics thus include slot-type F1 score and slotvalue CER.            Audio SNIPS is adopted, which synthesized multi-speaker utterances for SNIPS.            Following the standard split in SNIPS, US-accent speakers are further selected for training, and others are for validation/testing.          "},{name:"ST",description:'Speech Translation (ST) translates utterance into foreign words. To achieve this goal, the model has to perform ASR and MT simultaneously, which increases the difficulty. CoVoST2 En-De dataset is adopted while all the examples containing "REMOVE" are removed. The evaluation metric is case-sensitive detokenized BLEU.                 In the SUPERB Challenge, since it is too difficult to train the ST model with limited translation pairs, we first train on CoVoST2 En-De dataset and then finetuned on the training set of the hidden-set.\n                '}]},{name:"speaker",description:"speaker description",tasks:[{name:"SID",description:"            Speaker Identification, SID classifies each utterance for its speaker identity as a multi-class classification,             where speakers are in the same predefined set for both training and testing.            The widely used VoxCeleb1 [26] is adopted, and the evaluation metric is accuracy (ACC).          "},{name:"SV",description:"            Automatic Speaker Verification, ASV verifies whether the speakers of a pair of utterances match as a binary classification,             and speakers in the testing set may not appear in the training set.            Thus, ASV is more challenging than SID. VoxCeleb1 is used without VoxCeleb2 training data and noise augmentation.             The evaluation metric is equal error rate (EER).          "},{name:"SD",description:"            Speaker Diarization, SD predicts who is speaking when for each timestamp, and multiple speakers can speak simultaneously.            The model has to encode rich speaker characteristics for each frame and should be able to represent mixtures of signals.            LibriMix is adopted where LibriSpeech train-clean-100/dev-clean/test-clean are used to generate mixtures for training/validation/testing.            We focus on the two-speaker scenario as the first step.            The time-coded speaker labels were generated using alignments from Kaldi LibriSpeech ASR model.            The evaluation metric is diarization error rate (DER).          "}]},{name:"paralinguistics",description:"paralinguistics description",tasks:[{name:"ER",description:"            Emotion Recognition, ER predicts an emotion class for each utterance.            The most widely used ER dataset IEMOCAP is adopted, and we follow the conventional evaluation protocol:            we drop the unbalance emotion classes to leave the final four classes with a similar amount of data points and             cross-validates on five folds of the standard splits.            The evaluation metric is accuracy (ACC).          "}]},{name:"generation",description:"generation description",tasks:[{name:"SE",description:"Speech enhancement (SE) is the task of removing background noise from a degraded speech signal and improving the perceived quality and intelligibility of the signal. In SUPERB, we evaluate the speech enhancement problem on the VoiceBank-DEMAND corpus. A three layer BLSTM model is trained to predict the spectral mask for the clean signal. The prediction is transformed back to the time domain using inverse short-time Fourier transform (iSTFT). Our evaluation metrics cover various aspects of the speech enhancement quality. including Perceptual Evaluation of Speech Quality (PESQ) and ShortTime Objective Intelligibility (STOI)\n                "},{name:"SS",description:"Speech Separation (SS) is the task of separating target speech from background interference. It is an important step for speech processing, especially for noisy and multi-talker scenarios. In SUPERB, we investigate speech separation on the Libri2Mix dataset. We use the same 3-layer BLSTM model as the enhancement task, and permutation invariant training (PIT) is performed to optimize the objectives. The evaluation metric for speech separation is scale-invariant signal-to-distortion ratio improvement (SI-SDRi).\n                "}]}],re=[{name:"constrained",rules:Object(x.jsxs)("span",{children:["A fair comparison between"," ",Object(x.jsx)($,{children:"frozen representations"})," by enforcing the same downstream model in each task. Only a few hyper-paramters for training are allowed to tuned."]}),submit:"Make sure to read the rules before submitting.",Icon:H.a,theme:Object(u.a)(Z)},{name:"less-constrained",rules:Object(x.jsxs)("span",{children:["A comparison between ",Object(x.jsx)($,{children:"frozen representations"})," ","with customized but limited-resource downstream models. The details of downstream models are reported along with submissions."]}),submit:!1,Icon:U.a,theme:Object(u.a)(ee)},{name:"unconstrained",rules:Object(x.jsxs)("span",{children:["The track does not limit any approach for solving SUPERB tasks as long as it in principle utilizes only"," ",Object(x.jsx)($,{children:"a single shared model"})," with limited task-specific parameters."]}),submit:!1,Icon:M.a,theme:Object(u.a)(te)}],se=[{name:"all",theme:Object(u.a)(ne)},{name:"constrained",theme:Object(u.a)(Z)},{name:"less-constrained",theme:Object(u.a)(ee)},{name:"unconstrained",theme:Object(u.a)(te)}],oe=[{name:"public",theme:Object(u.a)(ne)},{name:"hidden",theme:Object(u.a)(ne)}],ce={PR_per_public:{header:"PR public",width:110,higherBetter:!1,isScore:!0,type:"number"},KS_acc_public:{header:"KS public",width:110,higherBetter:!0,isScore:!0,type:"number"},IC_acc_public:{header:"IC public",width:110,higherBetter:!0,isScore:!0,type:"number"},SID_acc_public:{header:"SID public",width:110,higherBetter:!0,isScore:!0,type:"number"},ER_acc_public:{header:"ER public",width:110,higherBetter:!0,isScore:!0,type:"number"},ERfold1_acc_public:{header:"ER fold1",width:110,higherBetter:!0,isScore:!0,type:"number"},ERfold2_acc_public:{header:"ER fold2",width:110,higherBetter:!0,isScore:!0,type:"number"},ERfold3_acc_public:{header:"ER fold3",width:110,higherBetter:!0,isScore:!0,type:"number"},ERfold4_acc_public:{header:"ER fold4",width:110,higherBetter:!0,isScore:!0,type:"number"},ERfold5_acc_public:{header:"ER fold5",width:110,higherBetter:!0,isScore:!0,type:"number"},ASR_wer_public:{header:"ASR public",width:120,higherBetter:!1,isScore:!0,type:"number"},ASR_LM_wer_public:{header:"ASR-LM public",width:140,higherBetter:!1,isScore:!0,type:"number"},QbE_mtwv_public:{header:"QbE public",width:120,higherBetter:!0,isScore:!0,type:"number"},SF_f1_public:{header:"SF-F1 public",width:130,higherBetter:!0,isScore:!0,type:"number"},SF_cer_public:{header:"SF-CER public",width:140,higherBetter:!1,isScore:!0,type:"number"},SV_eer_public:{header:"SV public",width:110,higherBetter:!1,isScore:!0,type:"number"},SD_der_public:{header:"SD public",width:110,higherBetter:!1,isScore:!0,type:"number"},ST_bleu_public:{header:"ST public",width:110,higherBetter:!0,isScore:!0,type:"number"},SE_pesq_public:{header:"SE-PESQ public",width:140,higherBetter:!0,isScore:!0,type:"number"},SE_stoi_public:{header:"SE-STOI public",width:140,higherBetter:!0,isScore:!0,type:"number"},SS_sisdri_public:{header:"SS public",width:110,higherBetter:!0,isScore:!0,type:"number"}},le={PR_per_hidden_dev:{header:"PR hidden dev",width:140,higherBetter:!1,isScore:!0,type:"number"},SID_acc_hidden_dev:{header:"SID hidden dev",width:140,higherBetter:!0,isScore:!0,type:"number"},ER_acc_hidden_dev:{header:"ER hidden dev",width:140,higherBetter:!0,isScore:!0,type:"number"},ASR_wer_hidden_dev:{header:"ASR hidden dev",width:140,higherBetter:!1,isScore:!0,type:"number"},QbE_map_hidden_dev:{header:"QbE-MAP hidden dev",width:180,higherBetter:!0,isScore:!0,type:"number"},QbE_eer_hidden_dev:{header:"QbE-EER hidden dev",width:180,higherBetter:!1,isScore:!0,type:"number"},SV_eer_hidden_dev:{header:"SV hidden dev",width:140,higherBetter:!1,isScore:!0,type:"number"},SD_der_hidden_dev:{header:"SD hidden dev",width:140,higherBetter:!1,isScore:!0,type:"number"},ST_bleu_hidden_dev:{header:"ST hidden dev",width:140,higherBetter:!0,isScore:!0,type:"number"},SS_sisdri_hidden_dev:{header:"SS hidden dev",width:140,higherBetter:!0,isScore:!0,type:"number"},SE_stoi_hidden_dev:{header:"SE-STOI hidden dev",width:180,higherBetter:!0,isScore:!0,type:"number"},SE_pesq_hidden_dev:{header:"SE-PESQ hidden dev",width:180,higherBetter:!0,isScore:!0,type:"number"}},de=Object(f.a)({aoeTimeUpload:{header:"Upolad Time",width:160,higherBetter:void 0,type:"alphanumeric"},submitName:{header:"Method",width:150,higherBetter:void 0,type:"alphanumeric"},modelDesc:{header:"Description",width:100,higherBetter:void 0,type:"alphanumeric"},modelURL:{header:"Model URL",width:100,higherBetter:void 0,type:"alphanumeric"},download:{header:"Download",width:100,higherBetter:void 0,type:"alphanumeric"},task:{header:"Track",width:130,higherBetter:void 0,type:"alphanumeric"},showOnLeaderboard:{header:"Show",width:70,higherBetter:void 0,type:"alphanumeric"},stride:{header:"Stride",width:100,higherBetter:void 0,type:"number"},inputFormat:{header:"Input Format",width:100,higherBetter:void 0,type:"alphanumeric"},corpus:{header:"Corpus",width:100,higherBetter:void 0,type:"alphanumeric"},paramDesc:{header:"Parameter Description",width:100,higherBetter:void 0,type:"alphanumeric"},paramShared:{header:"Shared parameters",width:100,higherBetter:void 0,type:"number"},fineTunedParam:{header:"Fine-tuned parameters",width:100,higherBetter:void 0,type:"number"},taskSpecParam:{header:"Task-specific parameters",width:100,higherBetter:void 0,type:"number"},state:{header:"State",width:70,higherBetter:void 0,type:"alphanumeric"},stateInfo:{header:"State Info",width:100,higherBetter:void 0,type:"alphanumeric"},submitUUID:{header:"Submission ID",width:300,higherBetter:void 0,type:"alphanumeric"}},ce),he=Object(f.a)({aoeTimeUpload:{header:"Upolad Time",width:160,higherBetter:void 0,type:"alphanumeric"},submitName:{header:"Method",width:150,higherBetter:void 0,type:"alphanumeric"},modelDesc:{header:"Description",width:100,higherBetter:void 0,type:"alphanumeric"},task:{header:"Track",width:130,higherBetter:void 0,type:"alphanumeric"},showOnLeaderboard:{header:"Show",width:70,higherBetter:void 0,type:"alphanumeric"},huggingfaceOrganizationName:{header:"Organization",width:130,higherBetter:void 0,type:"alphanumeric"},huggingfaceRepoName:{header:"Repository",width:130,higherBetter:void 0,type:"alphanumeric"},huggingfaceCommonHash:{header:"Commit",width:130,higherBetter:void 0,type:"alphanumeric"},paramShared:{header:"Shared parameters",width:100,higherBetter:void 0,type:"number"},state:{header:"State",width:100,higherBetter:void 0,type:"alphanumeric"},stateInfo:{header:"State Info",width:100,higherBetter:void 0,type:"alphanumeric"},submitUUID:{header:"Submission ID",width:300,higherBetter:void 0,type:"alphanumeric"}},le),ue=Object(f.a)({submitName:{header:"Method",width:150,higherBetter:void 0,type:"alphanumeric"},name:{header:"Name",width:100,higherBetter:void 0,type:"alphanumeric"},modelDesc:{header:"Description",width:100,higherBetter:void 0,type:"alphanumeric"},modelURL:{header:"URL",width:60,higherBetter:void 0,type:"alphanumeric"},aoeTimeUpload:{header:"Upolad Time",width:160,higherBetter:void 0,type:"alphanumeric"},task:{header:"Track",width:130,higherBetter:void 0,type:"alphanumeric"},stride:{header:"Stride",width:100,higherBetter:void 0,type:"number"},inputFormat:{header:"Input Format",width:100,higherBetter:void 0,type:"alphanumeric"},corpus:{header:"Corpus",width:100,higherBetter:void 0,type:"alphanumeric"},paramDesc:{header:"Parameter Description",width:100,higherBetter:void 0,type:"alphanumeric"},paramShared:{header:"Shared parameters",width:100,higherBetter:void 0,type:"number"},fineTunedParam:{header:"Fine-tuned parameters",width:100,higherBetter:void 0,type:"number"},taskSpecParam:{header:"Task-specific parameters",width:100,higherBetter:void 0,type:"number"}},ce),pe=Object(f.a)({submitName:{header:"Method",width:150,higherBetter:void 0,type:"alphanumeric"},modelDesc:{header:"Description",width:150,higherBetter:void 0,type:"alphanumeric"},name:{header:"Name",width:130,higherBetter:void 0,type:"alphanumeric"},aoeTimeUpload:{header:"Upolad Time",width:160,higherBetter:void 0,type:"alphanumeric"},task:{header:"Track",width:130,higherBetter:void 0,type:"alphanumeric"},paramShared:{header:"Shared parameters",width:100,higherBetter:void 0,type:"number"}},le),me={PR_per_public:[17.989999999999995,96.47],KS_acc_public:[41.3826674,96.66],IC_acc_public:[9.649354219,98.76],SID_acc_public:[20.058174,90.3],ER_acc_public:[48.23672168,67.62],ASR_wer_public:[76.82,96.38],QbE_mtwv_public:[.0058,.0736].map((function(e){return 100*e})),SF_f1_public:[69.64,89.81],SF_cer_public:[47.06,78.24],SV_eer_public:[90.44,94.89],SD_der_public:[89.95,94.38],ST_bleu_public:[2.32,20.01],SE_pesq_public:[2.55,2.64],SE_stoi_public:[93.6,94.2],SS_sisdri_public:[9.2341,10.4514],PR_per_hidden_dev:[.8100076941,.1632352551].map((function(e){return 100*(1-e)})),SID_acc_hidden_dev:[.4958333373,.7983333468].map((function(e){return 100*e})),ER_acc_hidden_dev:[.4712328911,.6794520617].map((function(e){return 100*e})),ASR_wer_hidden_dev:[.7356,.2149418249].map((function(e){return 100*(1-e)})),SV_eer_hidden_dev:[.255671,.127294].map((function(e){return 100*(1-e)})),SD_der_hidden_dev:[.157551825,.1048149392].map((function(e){return 100*(1-e)})),QbE_map_hidden_dev:[.1860194802,.5108585358].map((function(e){return 100*e})),QbE_eer_hidden_dev:[.3694903255,.1780432165].map((function(e){return 100*(1-e)})),ST_bleu_hidden_dev:[3.2,23.33],SS_sisdri_hidden_dev:[4.655592075,8.082589958],SE_pesq_hidden_dev:[1.510035692,1.567159144],SE_stoi_hidden_dev:[.8433188677,.8520344653].map((function(e){return 100*e}))},be=["PR_per_hidden_dev","SID_acc_hidden_dev","ER_acc_hidden_dev","ASR_wer_hidden_dev","QbE_map_hidden_dev","QbE_eer_hidden_dev","SV_eer_hidden_dev","SD_der_hidden_dev","ST_bleu_hidden_dev","SE_pesq_hidden_dev","SE_stoi_hidden_dev","SS_sisdri_hidden_dev"],ge=["PR_per_hidden_test","SID_acc_hidden_test","ER_acc_hidden_test","ASR_wer_hidden_test","QbE_map_hidden_test","QbE_eer_hidden_test","SV_eer_hidden_test","SD_der_hidden_test","ST_bleu_hidden_test","SE_pesq_hidden_test","SE_stoi_hidden_test","SS_sisdri_hidden_test"],je=n(307);function fe(e){var t=Object(w.a)(),n=e.title,a=void 0===n?"Title":n,i=e.titleColor,r=void 0===i?"textPrimary":i,s=e.titleVariant,o=void 0===s?"h4":s,c=e.description,l=void 0===c?null:c,d=e.descriptionColor,h=void 0===d?"textSecondary":d,u=e.descriptionVariant,b=void 0===u?"body1":u,g=e.textMaxWidth,j=void 0===g?750:g,f=e.divider,O=void 0===f||f;return Object(x.jsxs)(p.a,{margin:t.spacing(3,"auto"),children:[Object(x.jsxs)(p.a,{margin:t.spacing(2,"auto"),maxWidth:j,children:[Object(x.jsx)(m.a,{color:r,variant:o,children:a}),l&&Object(x.jsx)(p.a,{margin:t.spacing(1,"auto"),children:Object(x.jsx)(m.a,{color:h,variant:b,children:l})})]}),O&&Object(x.jsx)(A.a,{})]})}function Oe(e){return Object(x.jsx)(fe,Object(f.a)({},e))}function we(e){var t=G()(e,{titleVariant:{$set:"h5"}});return Object(x.jsx)(fe,Object(f.a)({},t))}function xe(e){var t=Object(g.a)(),n=Object(a.useRef)(null),i=Object(a.useState)(0),r=Object(o.a)(i,2),s=r[0],c=r[1];Object(a.useEffect)((function(){c(n.current.offsetWidth)}),[]);var l=Math.min(s,700),d={height:l/1920*1080,width:l,playerVars:{autoplay:0}};return Object(x.jsxs)(p.a,{ref:n,margin:t.spacing(0,0,8),children:[Object(x.jsx)(p.a,{margin:t.spacing(8,"auto",1),children:Object(x.jsx)(m.a,{variant:"h2",color:"textPrimary",children:Object(x.jsx)("strong",{children:"SUPERB"})})}),Object(x.jsx)(p.a,{margin:t.spacing(1,"auto",6),children:Object(x.jsxs)(m.a,{variant:Object(j.a)(t.breakpoints.up("sm"))?"h4":"h5",color:"textPrimary",children:[Object(x.jsx)("strong",{children:"S"}),"peech processing ",Object(x.jsx)("strong",{children:"U"}),"niversal ",Object(x.jsx)("strong",{children:"PER"}),"formance ",Object(x.jsx)("strong",{children:"B"}),"enchmark"]})}),Object(x.jsxs)(p.a,{margin:t.spacing(1,"auto",6),children:[Object(x.jsxs)("p",{children:[Object(x.jsx)("strong",{children:Object(x.jsx)("a",{href:ae,target:"_blank",rel:"noopener noreferrer",children:"Subscribe"})})," our e-news to receive all the latest information about SUPERB or ",Object(x.jsx)("strong",{children:"contact us"})," via"]}),Object(x.jsx)("p",{children:Object(x.jsx)("strong",{children:Object(x.jsx)("a",{href:"mailto:superb.announcement@gmail.com",target:"_blank",children:"superb.announcement@gmail.com"})})})]}),Object(x.jsxs)(p.a,{maxWidth:800,margin:t.spacing(1,"auto",6),children:[Object(x.jsx)(m.a,{variant:"h6",color:"textPrimary",children:Object(x.jsx)("strong",{children:"2021 SUPERB Challenge Timeline"})}),Object(x.jsxs)("span",{align:"left",children:[Object(x.jsx)(R.a,{to:"/challenge#top",children:"Challenge Policy"}),Object(x.jsxs)("ul",{children:[Object(x.jsxs)("li",{children:[Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Sep 18, 2021"}),": ",Object(x.jsx)(R.a,{to:"/news#announcement2021",children:"Challenge announcement"})," & "]}),Object(x.jsx)("a",{href:"https://github.com/s3prl/s3prl",target:"_blank",rel:"noopener",children:Object(x.jsx)("span",{children:"S3PRL"})}),Object(x.jsx)("span",{children:" released"})]}),Object(x.jsxs)("li",{children:[Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Sep 30, 2021"}),": ",Object(x.jsx)(R.a,{to:"/challenge#Overall-Metrics",children:"Overall metrics"})," announcement & "]}),Object(x.jsx)(R.a,{to:"/leaderboard?subset=Public+Set&track=constrained",children:"public-set leaderboard"}),Object(x.jsxs)("span",{children:[" is online and ",Object(x.jsx)(R.a,{to:"/submit?type=public",children:"accepts submissions"})]})]}),Object(x.jsx)("li",{children:Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Oct 15, 2021"}),": ",Object(x.jsx)(R.a,{to:"/leaderboard?subset=Hidden+Dev+Set&track=constrained",children:"Hidden-set leaderboard"})," is online and ",Object(x.jsx)(R.a,{to:"/submit?type=hidden",children:"accepts submissions"})]})}),Object(x.jsxs)("li",{children:[Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Nov 12, 2021"}),": "]}),Object(x.jsx)("a",{href:"https://aaai-sas-2022.github.io/",target:"_blank",rel:"noopener",children:Object(x.jsx)("span",{children:"AAAI workshop"})}),Object(x.jsx)("span",{children:" paper submission deadline (encouraged)"})]}),Object(x.jsxs)("li",{children:[Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Dec 3, 2021"}),": "]}),Object(x.jsx)("a",{href:"https://aaai-sas-2022.github.io/",target:"_blank",rel:"noopener",children:Object(x.jsx)("span",{children:"AAAI workshop"})}),Object(x.jsx)("span",{children:" paper acceptance / rejection announcement"})]}),Object(x.jsx)("li",{children:Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Jan 10, 2022"}),": Hidden-set leaderboard submission deadline"]})}),Object(x.jsx)("li",{children:Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Jan 13, 2022"}),": Submission selection & system description paper deadline"]})}),Object(x.jsx)("li",{children:Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Jan 20, 2022"}),": Winner announcement & reveal hidden-set private scores"]})}),Object(x.jsxs)("li",{children:[Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Jan 22, 2022"}),": AAAI late "]}),Object(x.jsx)("a",{href:"https://aaai.org/Conferences/AAAI-21/registration/",target:"_blank",rel:"noopener",children:Object(x.jsx)("span",{children:"registration"})}),Object(x.jsx)("span",{children:" deadline"})]}),Object(x.jsxs)("li",{children:[Object(x.jsx)("span",{children:"Feb 28 - Mar 1, 2022: "}),Object(x.jsx)("a",{href:"https://aaai-sas-2022.github.io/",target:"_blank",rel:"noopener",children:Object(x.jsx)("span",{children:"AAAI workshop"})}),Object(x.jsx)("span",{children:" presentation"})]})]})]})]}),Object(x.jsx)(je.a,{videoId:"zd9fiVvej0k",opts:d}),Object(x.jsxs)(p.a,{maxWidth:800,margin:"auto",textAlign:"left",children:[Object(x.jsxs)(y,{children:[Object(x.jsx)(k,{children:Object(x.jsxs)(m.a,{component:"span",variant:"body1",color:"textSecondary",children:["SUPERB is a collection of benchmarking resources to evaluate the capability of a universal shared representation for speech processing.SUPERB consists of the following:",Object(x.jsx)("div",{style:{width:"fit-content",margin:"auto",textAlign:"left"},children:Object(x.jsxs)("ol",{children:[Object(x.jsx)("li",{children:"A benchmark of ten speech processing tasks[1]built on established public datasets,"}),Object(x.jsxs)("li",{children:["A",Object(x.jsx)(B,{name:Object(x.jsx)("a",{children:"benchmark toolkit"}),link:"https://github.com/s3prl/s3prl"}),"designed to evaluate and analyze pretrained model performance on various downstream tasks following the conventional evaluation protocols from speech communities,"]}),Object(x.jsxs)("li",{children:["A public",Object(x.jsx)(B,{name:Object(x.jsx)("a",{children:"leaderboard"}),link:"/leaderboard"}),"for"," ",Object(x.jsx)(B,{name:Object(x.jsx)("a",{children:"submissions"}),link:"/submit"}),"and performance tracking on the benchmark."]})]})})]})}),Object(x.jsx)(k,{children:Object(x.jsx)(m.a,{variant:"body1",color:"textSecondary",children:"SUPERB aims to offer the community a standard and comprehensive framework to train, evaluate, and compare the generalizability of universal speech representations on speech processing tasks.A universal speech representation can be leveraged to quickly adapt to diverse downstream tasks with minimum architectural change and downstream fine-tuning, so as to reduce the model development cycle time for new tasks.To emphasize on evaluating the quality of the learned universal representation, SUPERB puts an explicit constraint on the downstream model and limits its parameter size."})}),Object(x.jsx)(k,{children:Object(x.jsx)(m.a,{variant:"body1",color:"textSecondary",children:"The ultimate goal of SUPERB is to democratize the advancement in speech processing with powerful, generalizable, and reusable speech representations. SUPERB is a long-term maintained and continuously developing project.As we are gradually releasing new tasks and opening new tracks, we invite researchers to participate in the challenge and advance the research frontier together."})}),Object(x.jsx)(k,{children:Object(x.jsxs)(m.a,{variant:"body1",color:"textSecondary",children:["We also want to let you know that ",Object(x.jsx)("a",{href:"https://signalprocessingsociety.org/blog/ieee-jstsp-special-issue-self-supervised-learning-speech-and-audio-processing",target:"_blank",rel:"noopener noreferrer",children:"IEEE JSTSP Special Issue on Self-Supervised Learning for Speech and Audio Processing"})," is call-for-paper.The deadline is ",Object(x.jsx)($,{children:"December 31, 2021"}),".The research based on SUPERB will be very suitable for the special issue.If you have any questions about the special issue, please feel free to contact Hung-yi Lee (",Object(x.jsx)("a",{href:"mailto:hungyilee@ntu.edu.tw",target:"_blank",rel:"noopener noreferrer",children:"hungyilee@ntu.edu.tw"}),")."]})})]}),Object(x.jsx)(y,{children:Object(x.jsx)(b.a,{container:!0,justify:"space-evenly",spacing:0,children:[["ntu-1000.png","https://www.ntu.edu.tw/english/"],["cmu-1000.png","https://www.cmu.edu/"],["mit-1000.png","https://www.mit.edu/"],["jhu-1000.png","https://www.jhu.edu/"],["fair-1000.png","https://ai.facebook.com/"],["lxt-1000.png","https://www.lxt.ai/"],["huggingface-1000.png","https://huggingface.co/"]].map((function(e){return Object(x.jsx)(b.a,{item:!0,xs:6,sm:4,md:4,children:Object(x.jsx)("a",{target:"_blank",href:e[1],children:Object(x.jsx)("img",{src:e[0],width:"100%"})})},e[0])}))})}),Object(x.jsxs)(p.a,{margin:t.spacing(8,0),textAlign:"center",children:[Object(x.jsx)(Oe,{title:"Acknowledgement"}),Object(x.jsxs)(m.a,{variant:"body1",color:"textSecondary",children:["We thank ",Object(x.jsx)(B,{name:Object(x.jsx)("a",{children:"Ming-Yang Ho"}),link:"https://kaminyou.com/"})," for creating and maintaining the SUPERB official website."]})]})]})]})}n(397);var ve=[{title:"2021 SUPERB Challenge Timeline",date:new Date(2021,8,18),content:Object(x.jsxs)("span",{align:"left",children:[Object(x.jsx)(R.a,{to:"/challenge#top",children:"Challenge Policy"}),Object(x.jsxs)("ul",{children:[Object(x.jsxs)("li",{children:[Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Sep 18, 2021"}),": ",Object(x.jsx)(R.a,{to:"/news#announcement2021",children:"Challenge announcement"})," & "]}),Object(x.jsx)("a",{href:"https://github.com/s3prl/s3prl",target:"_blank",rel:"noopener",children:Object(x.jsx)("span",{children:"S3PRL"})}),Object(x.jsx)("span",{children:" released"})]}),Object(x.jsxs)("li",{children:[Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Sep 30, 2021"}),": Overall metrics announcement & "]}),Object(x.jsx)("a",{href:"https://superbbenchmark.org/leaderboard",target:"_blank",rel:"noopener",children:Object(x.jsx)("span",{children:"public-set leaderboard"})}),Object(x.jsx)("span",{children:" is online and accepts submissions"})]}),Object(x.jsx)("li",{children:Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Oct 15, 2021"}),": Hidden-set leaderboard is online and accepts submissions"]})}),Object(x.jsxs)("li",{children:[Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Nov 12, 2021"}),": "]}),Object(x.jsx)("a",{href:"https://aaai-sas-2022.github.io/",target:"_blank",rel:"noopener",children:Object(x.jsx)("span",{children:"AAAI workshop"})}),Object(x.jsx)("span",{children:" paper submission deadline (encouraged)"})]}),Object(x.jsxs)("li",{children:[Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Dec 3, 2021"}),": "]}),Object(x.jsx)("a",{href:"https://aaai-sas-2022.github.io/",target:"_blank",rel:"noopener",children:Object(x.jsx)("span",{children:"AAAI workshop"})}),Object(x.jsx)("span",{children:" paper acceptance / rejection announcement"})]}),Object(x.jsx)("li",{children:Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Jan 10, 2022"}),": Hidden-set leaderboard submission deadline"]})}),Object(x.jsx)("li",{children:Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Jan 13, 2022"}),": Submission selection & system description paper deadline"]})}),Object(x.jsx)("li",{children:Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Jan 20, 2022"}),": Winner announcement & reveal hidden-set private scores"]})}),Object(x.jsxs)("li",{children:[Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:"Jan 22, 2022"}),": AAAI late "]}),Object(x.jsx)("a",{href:"https://aaai.org/Conferences/AAAI-21/registration/",target:"_blank",rel:"noopener",children:Object(x.jsx)("span",{children:"registration"})}),Object(x.jsx)("span",{children:" deadline"})]}),Object(x.jsxs)("li",{children:[Object(x.jsx)("span",{children:"Feb 28 - Mar 1, 2022: "}),Object(x.jsx)("a",{href:"https://aaai-sas-2022.github.io/",target:"_blank",rel:"noopener",children:Object(x.jsx)("span",{children:"AAAI workshop"})}),Object(x.jsx)("span",{children:" presentation"})]})]})]})},{title:"Announcing 2021 SUPERB Challenge",id:"announcement2021",date:new Date(2021,8,18),content:Object(x.jsxs)("span",{align:"left",children:[Object(x.jsxs)("div",{children:["We are pleased to announce that the ",Object(x.jsx)($,{children:"2021 SUPERB Challenge"})," will be kicked off in ",Object(x.jsx)($,{children:"Oct 2021"})," and the results will be presented in ",Object(x.jsx)($,{children:"February 2022"})," in a reserved session at ",Object(x.jsx)("a",{href:"https://aaai-sas-2022.github.io",target:"_blank",rel:"noopener",children:"The 2nd Self-supervised Learning for Audio and Speech Processing workshop at AAAI"})," in Vancouver.The challenge policy can be found at ",Object(x.jsx)(R.a,{to:"/challenge#top",children:"here"}),".Submission system will be open in early ",Object(x.jsx)($,{children:"Oct 2021"}),"."]}),Object(x.jsx)("br",{}),Object(x.jsxs)("div",{children:["We encourage participants to submit (non-archival, cross-submission is possible after consulting organizers) workshop papers to share their results with the community and inspire future collaborations. In light of the tight AAAI deadlines, we encourage participants to submit papers based on results from the development dataset of the challenge, which is publicly available and can be evaluated directly by the participants. Workshop papers will be reviewed and acceptance will be determined based on the quality of the work. Participants can obtain results on hidden (surprise) dataset through the challenge\u2019s model submission system that will be open from ",Object(x.jsx)($,{children:"Oct 2021"})," all the way to ",Object(x.jsx)($,{children:"Jan 2022"}),". Authors of the accepted papers should update hidden set results in their paper, and send the final paper to the organizers for verification by ",Object(x.jsx)($,{children:"Jan 13, 2022"}),". Performance on the hidden set will not be judged during the verification process."]})]})}],Se=Object(d.a)((function(e){return{taskName:{fontWeight:"bold",marginBottom:e.spacing(2)}}}));function ye(e){return Object(x.jsx)(h.a,{children:Object(x.jsx)(p.a,{maxWidth:1e3,margin:"auto",children:Object(x.jsxs)(S,{id:e.id,children:[Object(x.jsx)(Oe,{title:e.title,titleVariant:"h5",divider:!0,color:"textPrimary"}),Object(x.jsx)(m.a,{variant:"body1",color:"textSecondary",align:"right",style:{fontSize:10},children:Object(x.jsxs)(p.a,{fontStyle:"italic",children:["published on ",e.date.toDateString()]})}),Object(x.jsx)(m.a,{variant:"body1",color:"textSecondary",children:e.content})]})})})}var ke=function(e){Se();var t=Object(g.a)();return Object(x.jsxs)(i.a.Fragment,{children:[Object(x.jsx)(S,{margin:t.spacing(8,"auto",1),children:Object(x.jsx)(Oe,{title:"News",description:Object(x.jsxs)("span",{children:[Object(x.jsx)($,{children:Object(x.jsx)("a",{href:ae,target:"_blank",rel:"noopener noreferrer",children:"Subscribe"})})," our e-news to receive all the latest information about SUPERB."]})})}),ve.map(ye)]})},_e=n(784);function Te(e){var t=e.elevation,n=void 0===t?3:t,a=e.liftDegree,r=void 0===a?6:a,s=Object(O.a)(e,["elevation","liftDegree"]),c=i.a.useState(!1),l=Object(o.a)(c,2),d=l[0],h=l[1];return Object(x.jsx)(_e.a,Object(f.a)(Object(f.a)({},s),{},{elevation:d?n+r:n,onMouseOver:function(){h((function(e){return!e}))},onMouseOut:function(){h((function(e){return!e}))}}))}var Ae=Object(d.a)((function(e){return{taskName:{fontWeight:"bold",marginBottom:e.spacing(2)}}}));var Re=function(e){var t=Ae(),n=Object(g.a)(),a=i.a.useState({top:!1,left:!1,bottom:!1,right:!1}),r=Object(o.a)(a,2);return r[0],r[1],Object(x.jsxs)(i.a.Fragment,{children:[Object(x.jsxs)(S,{margin:n.spacing(8,"auto",1),children:[Object(x.jsx)(Oe,{title:"Tasks",description:Object(x.jsxs)("span",{children:["General speech processing can be categorized into"," ",Object(x.jsx)($,{children:"discriminative"})," and ",Object(x.jsx)($,{children:"generative"})," ","tasks. The initial release of SUPERB focues on the former, where ten tasks are collected from ",Object(x.jsx)($,{children:"six domains"}),"."]})}),Object(x.jsx)(b.a,{container:!0,direction:"row",spacing:2,justify:"center",children:ie.map((function(e){var t=e.name;return Object(x.jsx)(b.a,{item:!0,children:Object(x.jsx)(E,{link:"/tasks#".concat(t),children:Object(x.jsx)(T.a,{variant:"outlined",children:L(t.toLowerCase())})})})}))})]}),ie.map((function(e){var a=e.name,i=e.description,r=e.tasks;return Object(x.jsxs)(S,{anchorKey:a,margin:n.spacing(8,"auto",1),children:[Object(x.jsx)(Oe,{title:L(a.toLowerCase()),description:i}),Object(x.jsx)(b.a,{container:!0,spacing:5,justify:"center",children:r.map((function(e){var a=e.name,i=e.description;return Object(x.jsx)(b.a,{item:!0,xs:12,sm:6,md:4,className:t.taskCard,children:Object(x.jsx)(Te,{elevation:3,children:Object(x.jsxs)(p.a,{padding:n.spacing(3,2),children:[Object(x.jsx)(m.a,{color:"textPrimary",variant:"h6",className:t.taskName,children:"".concat(a)}),Object(x.jsx)(m.a,{color:"textSecondary",variant:"body2",children:i})]})})})}))})]})}))]})},Pe=n(849),Ee=n(310),Ce=n.n(Ee),Be=n(874),Ne=n(879),Le=n(842);function $e(e){var t=e.type,n=e.onTypeChange,a=function(e){var t=e.toLowerCase();return"public"===t?"Paper / Challenge Public":"hidden"===t?"Challenge Hidden":void 0};return Object(x.jsx)("div",{className:"select group",style:{width:"fit-content",maxWidth:"100%",margin:"auto"},children:Object(x.jsx)(Ne.a,{row:!0,"aria-label":"position",name:"position",defaultValue:"constrained",value:t,onChange:n,children:oe.map((function(e){return Object(x.jsx)(h.a,{theme:e.theme,children:Object(x.jsx)(Le.a,{value:e.name,control:Object(x.jsx)(Be.a,{color:"primary"}),label:Object(x.jsx)(m.a,{color:"primary",children:a(e.name)}),color:"primary"})})}))})})}var Ie=n(17),De=n.n(Ie),ze=n(36),He=n(107),Fe=n(58),Ue=n.n(Fe),We=n(45),Me=n.n(We),qe=n(845),Ve=n(785),Ye=Object(a.createContext)({isLoggedIn:!1,userId:null,token:null,isAdmin:!1,email:null,login:function(){},logout:function(){}}),Qe=n(311),Je=n.n(Qe),Ke=function(e){return 0===e.length||(!!(e.match(/^[eE0-9]+$/)&&e.length<=100)||"Invalid Number")},Ge={submitName:{required:"This field is requied.",maxLength:{value:20,message:"Submission name should be less then 20 charaters"}},modelURL:{validate:{isGithub:function(e){return!(e&&!Je()(e))||"Invalid Github URL"}}},modelDesc:{required:"This field is required",maxLength:{value:300,message:"Submission name should not excced 300 charaters"}},stride:{required:"This field is required",pattern:{value:/^[0-9]*$/,message:"Invalid number"},max:{value:100,message:"Invalid number"},min:{value:0,message:"Invalid number"}},inputFormat:{required:"This field is required",maxLength:{value:300,message:"Input fromat should not excced 300 charaters"}},corpus:{required:"This field is required",maxLength:{value:300,message:"Corpus should not excced 300 charaters"}},paramDesc:{required:"This field is required",maxLength:{value:300,message:"Parameter description should not excced 300 charaters"}},paramShared:{required:"This field is required",validate:{validNum:function(e){return Ke(e)}}},fineTunedParam:{validate:{validNum:function(e){return Ke(e)}}},taskSpecParam:{validate:{validNum:function(e){return Ke(e)}}},file:{required:"No file selected",validate:{fileType:function(e){return"application/zip"===e[0].type||"application/x-zip-compressed"===e[0].type||"application/x-zip"===e[0].type||"Wrong file format"},fileSize:function(e){var t;return(null===(t=e[0])||void 0===t?void 0:t.size)<52428800||"File too large"}}},huggingfaceOrganizationName:{required:"This field is requied.",maxLength:{value:60,message:"Huggingface Organization Name should be over 60 charaters"}},huggingfaceRepoName:{required:"This field is requied.",maxLength:{value:60,message:"Huggingface Repository Name should be over 60 charaters"}},huggingfaceCommonHash:{required:"This field is requied.",maxLength:{value:40,message:"Huggingface Common Hash should be equal to 40 charaters"},minLength:{value:40,message:"Huggingface Common Hash should be equal to 40 charaters"}}},Xe=n(880),Ze=n(848),et=Object(d.a)((function(e){return{paper:{border:"1px solid",padding:e.spacing(.7),backgroundColor:e.palette.background.paper,fontSize:"medium"}}})),tt=function(e){var t=e.control,n=e.className,i=e.name,r=e.label,s=e.description,c=e.rules,l=e.error,d=e.helperText,h=Object(a.useState)(null),u=Object(o.a)(h,2),p=u[0],m=u[1],b=et();return Object(x.jsxs)(x.Fragment,{children:[Object(x.jsx)(He.a,{control:t,name:i,render:function(e){var t=e.field;return Object(x.jsx)(Xe.a,Object(f.a)(Object(f.a)({},t),{},{className:n,label:r,onFocus:function(e){return m(e.currentTarget)},onBlur:function(e){return m(null)},fullWidth:!0,error:l,helperText:d}))},rules:c}),Object(x.jsx)(Ze.a,{open:Boolean(p),anchorEl:p,placement:"right-start",transition:!0,style:{maxWidth:"27%"},children:Object(x.jsx)("div",{className:b.paper,children:s})})]})},nt=Object(d.a)((function(e){return{root:{width:"60%",marginLeft:"auto",marginRight:"auto"},textField:{marginBottom:e.spacing(1),width:"80%"},Button:{display:"block",marginLeft:"auto",marginRight:"auto",marginTop:e.spacing(2),marginBottom:"3%"}}}));function at(){var e=nt(),t=Object(a.useRef)(),n=Object(c.f)(),i=Object(a.useState)(!1),r=Object(o.a)(i,2),s=r[0],l=r[1],d=Object(He.b)({defaultValues:{submitName:"",modelURL:"",modelDesc:"",stride:"",inputFormat:"",corpus:"",paramDesc:"",paramShared:"",fineTunedParam:"",taskSpecParam:"",task:"1"}}),u=d.control,p=d.handleSubmit,b=d.register,g=d.formState.errors,j=d.setValue,w=d.watch,v=b("file",Ge.file),y=v.ref,_=(Object(O.a)(v,["ref"]),Object(a.useContext)(Ye)),A=w("file"),P=function(){var e=Object(ze.a)(De.a.mark((function e(t){var a;return De.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return e.prev=0,l(!0),(a=new FormData).append("submitName",t.submitName),a.append("modelURL",t.modelURL),a.append("modelDesc",t.modelDesc),a.append("stride",t.stride),a.append("inputFormat",t.inputFormat),a.append("corpus",t.corpus),a.append("paramDesc",t.paramDesc),a.append("paramShared",t.paramShared),a.append("fineTunedParam",t.fineTunedParam),a.append("taskSpecParam",t.taskSpecParam),a.append("task",t.task),a.append("file",null===t||void 0===t?void 0:t.file[0]),e.next=17,Me()({method:"post",url:"/api/submission",data:a,headers:{Authorization:"Bearer "+_.token}}).then((function(e){l(!1),Ue()({title:"Susscess",text:e.data.message,icon:"success"}).then((function(){return n.push("/profile")}))})).catch((function(e){l(!1),Ue()({title:"Error",text:e.response.data.message,icon:"error"})}));case 17:e.sent,e.next=22;break;case 20:e.prev=20,e.t0=e.catch(0);case 22:case"end":return e.stop()}}),e,null,[[0,20]])})));return function(t){return e.apply(this,arguments)}}();function E(){var n,a;return Object(x.jsxs)(S,{children:[Object(x.jsx)(k,{children:Object(x.jsxs)(m.a,{variant:"body1",color:"textSecondary",children:["Make sure to read the ",Object(x.jsx)(R.a,{to:"/rules",children:"Rules"})," before submitting to the ",Object(x.jsx)(R.a,{to:"/leaderboard?track=constrained&subset=Paper",children:"SUPERB Benchmark"})," or the ",Object(x.jsx)(R.a,{to:"/leaderboard?track=constrained&subset=Public+Set",children:"SUPERB Challenge Public-set"}),"."]})}),Object(x.jsxs)("form",{className:e.root,autoComplete:"off",onSubmit:p(P),children:[Object(x.jsx)(tt,{control:u,className:e.textField,name:"submitName",label:"Submission Name*",description:"A short name for your system, which will be displayed on the leaderboard. (Required)",rules:Ge.submitName,error:g.submitName,helperText:g.submitName&&g.submitName.message}),Object(x.jsx)(tt,{control:u,className:e.textField,name:"modelURL",label:"Model URL/Github",description:"A Github URL for your model code repository. (Optional)",rules:Ge.modelURL,error:g.modelURL,helperText:g.modelURL&&g.modelURL.message}),Object(x.jsx)(tt,{control:u,className:e.textField,name:"modelDesc",label:"Model Description*",description:"A sentence or two describing your system. Make sure to mention any outside data you use. (Required)",rules:Ge.modelDesc,error:g.modelDesc,helperText:g.modelDesc&&g.modelDesc.message}),Object(x.jsx)(tt,{control:u,className:e.textField,name:"stride",label:"Stride*",description:"Your stride width (ms). (Required)",rules:Ge.stride,error:g.stride,helperText:g.stride&&g.stride.message}),Object(x.jsx)(tt,{control:u,className:e.textField,name:"inputFormat",label:"Input Format*",description:"The type of input format you use. e.g., waveform, FBANK. (Required) ",rules:Ge.inputFormat,error:g.inputFormat,helperText:g.inputFormat&&g.inputFormat.message}),Object(x.jsx)(tt,{control:u,className:e.textField,name:"corpus",label:"Corpus*",description:"The type of corpus you use. e.g., LS 50 hr, LL 60k hr. (Required)",rules:Ge.corpus,error:g.corpus,helperText:g.corpus&&g.corpus.message}),Object(x.jsx)(tt,{control:u,className:e.textField,name:"paramDesc",label:"Parameter Description*",description:"A sentence or explaining how you share parameters accross tasks (or stating that you don't share parameters). (Required)",rules:Ge.paramDesc,error:g.paramDesc,helperText:g.paramDesc&&g.paramDesc.message}),Object(x.jsx)(tt,{control:u,className:e.textField,name:"paramShared",label:"Parameter shared without fine-tuning*",description:"The total number of parameters in your model which don't require task spesific fine-tuning (only numeric numbers allowed). (Required)",rules:Ge.paramShared,error:g.paramShared,helperText:g.paramShared&&g.paramShared.message}),Object(x.jsx)(tt,{control:u,className:e.textField,name:"fineTunedParam",label:"Fine-tuned parameters",description:"The number of parameters in your model which are common but require task specific fine-tuning (only numeric numbers allowed). (Optional)",rules:Ge.fineTunedParam,error:g.fineTunedParam,helperText:g.fineTunedParam&&g.fineTunedParam.message}),Object(x.jsx)(tt,{control:u,className:e.textField,name:"taskSpecParam",label:"Task-Specific parameters",description:"The number of parameters in your model which are task specific and not used by any other tasks (only numeric numbers allowed). (Optional)",rules:Ge.taskSpecParam,error:g.taskSpecParam,helperText:g.taskSpecParam&&g.taskSpecParam.message}),Object(x.jsxs)(qe.a,{component:"fieldset",style:{marginTop:"2%"},children:[Object(x.jsx)(Ve.a,{component:"legend",children:Object(x.jsx)(R.a,{to:"/rules",children:"Track"})}),Object(x.jsx)(He.a,{control:u,name:"task",render:function(e){var t=e.field;return Object(x.jsx)(Ne.a,Object(f.a)(Object(f.a)({row:!0,"aria-label":"position"},t),{},{children:re.map((function(e,t){return Object(x.jsx)(h.a,{theme:e.theme,children:Object(x.jsx)(Le.a,{value:(t+1).toString(),control:Object(x.jsx)(Be.a,{color:"primary"}),label:Object(x.jsx)(m.a,{color:"primary",children:L(e.name.toLowerCase())}),color:"primary"})})}))}))}})]}),Object(x.jsx)("input",{type:"file",accept:".zip",style:{display:"none"},name:"file",ref:function(e){y(e),t.current=e},onChange:function(e){return j("file",e.target.files)}}),Object(x.jsx)(T.a,{className:e.Button,variant:"contained",color:"primary",onClick:function(){return t.current.click()},children:A&&(null===(n=A[0])||void 0===n?void 0:n.name)?null===(a=A[0])||void 0===a?void 0:a.name:"Select zip"}),Object(x.jsx)("span",{style:{color:"red"},children:g.file&&g.file.message}),Object(x.jsx)(T.a,{className:e.Button,variant:"contained",color:"primary",type:"submit",disabled:s,children:s?"Submitting...":"Submit"})]})]})}return Object(x.jsx)(E,{})}var it=Object(d.a)((function(e){return{root:{width:"60%",marginLeft:"auto",marginRight:"auto"},textField:{marginBottom:e.spacing(1),width:"80%"},Button:{display:"block",marginLeft:"auto",marginRight:"auto",marginTop:e.spacing(2),marginBottom:"3%"}}}));function rt(){var e=it(),t=Object(c.f)(),n=Object(a.useState)(!1),i=Object(o.a)(n,2),r=i[0],s=i[1],l=Object(He.b)({defaultValues:{submitName:"",huggingfaceOrganizationName:"",huggingfaceRepoName:"",huggingfaceCommonHash:"",paramShared:"",task:"1"}}),d=l.control,u=l.handleSubmit,p=l.formState.errors,b=Object(a.useContext)(Ye),g=function(){var e=Object(ze.a)(De.a.mark((function e(n){var a;return De.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return e.prev=0,s(!0),(a=new FormData).append("submitName",n.submitName),a.append("modelDesc",n.modelDesc),a.append("huggingfaceOrganizationName",n.huggingfaceOrganizationName),a.append("huggingfaceRepoName",n.huggingfaceRepoName),a.append("huggingfaceCommonHash",n.huggingfaceCommonHash),a.append("paramShared",n.paramShared),a.append("task",n.task),e.next=12,Me()({method:"post",url:"/api/hiddensubmission",data:a,headers:{Authorization:"Bearer "+b.token}}).then((function(e){s(!1),Ue()({title:"Susscess",text:e.data.message,icon:"success"}).then((function(){return t.push("/profile")}))})).catch((function(e){s(!1),Ue()({title:"Preparing...",text:e.response.data.message,icon:"error"})}));case 12:e.sent,e.next=17;break;case 15:e.prev=15,e.t0=e.catch(0);case 17:case"end":return e.stop()}}),e,null,[[0,15]])})));return function(t){return e.apply(this,arguments)}}();function j(){return Object(x.jsxs)(S,{children:[Object(x.jsx)(k,{children:Object(x.jsxs)(m.a,{variant:"body1",color:"textSecondary",children:[Object(x.jsxs)("p",{children:["Please ",Object(x.jsx)("a",{target:"_blank",href:"https://huggingface.co/superb/superb-submission",children:"Upload your model"})," before the submitting to the ",Object(x.jsx)(R.a,{to:"/leaderboard?track=constrained&subset=Hidden+Dev+Set",children:"SUPERB Challenge Hidden-set"}),"."]}),Object(x.jsxs)("p",{children:["If you wish to submit pre-trained models in non-PyTorch frameworks, please ",Object(x.jsx)("a",{href:"https://docs.google.com/forms/d/e/1FAIpQLSe52jYL2Yk9oYqXfg_Bg0Sjp01a6HSLUhY5VohsZOE5sNmgsw/viewform",children:"fill this form"}),"."]}),Object(x.jsxs)("p",{children:["If you are not feasible to submit the pre-trained model, please ",Object(x.jsx)("a",{href:"https://docs.google.com/forms/d/e/1FAIpQLSdA44nArlIDfGV63WwtwXer4WAPQO1aBwEpAjDSNjbMQN-GJQ/viewform",children:"fill this form"})," for us to see how to help!"]})]})}),Object(x.jsxs)("form",{className:e.root,autoComplete:"off",onSubmit:u(g),children:[Object(x.jsx)(tt,{control:d,className:e.textField,name:"submitName",label:"Submission Name*",description:"A short name for your system, which will be displayed on the leaderboard. (Required)",rules:Ge.submitName,error:p.submitName,helperText:p.submitName&&p.submitName.message}),Object(x.jsx)(tt,{control:d,className:e.textField,name:"modelDesc",label:"Model Description*",description:"A sentence or two describing your system. Make sure to mention any outside data you use. (Required)",rules:Ge.modelDesc,error:p.modelDesc,helperText:p.modelDesc&&p.modelDesc.message}),Object(x.jsx)(tt,{control:d,className:e.textField,name:"huggingfaceOrganizationName",label:"Huggingface Organization Name*",description:"Organization Name of your huggingface model hub. (Required)",rules:Ge.huggingfaceOrganizationName,error:p.huggingfaceOrganizationName,helperText:p.huggingfaceOrganizationName&&p.huggingfaceOrganizationName.message}),Object(x.jsx)(tt,{control:d,className:e.textField,name:"huggingfaceRepoName",label:"Huggingface Repository Name*",description:"Repository Name for your model. (Required)",rules:Ge.huggingfaceRepoName,error:p.huggingfaceRepoName,helperText:p.huggingfaceRepoName&&p.huggingfaceRepoName.message}),Object(x.jsx)(tt,{control:d,className:e.textField,name:"huggingfaceCommonHash",label:"Huggingface Commit Hash (full 40 characters)*",description:"Commit hash (full 40 characters) of your model. (Required)",rules:Ge.huggingfaceCommonHash,error:p.huggingfaceCommonHash,helperText:p.huggingfaceCommonHash&&p.huggingfaceCommonHash.message}),Object(x.jsx)(tt,{control:d,className:e.textField,name:"paramShared",label:"Parameter shared without fine-tuning*",description:"The total number of parameters in your model which don't require task spesific fine-tuning (only numeric numbers allowed). (Required)",rules:Ge.paramShared,error:p.paramShared,helperText:p.paramShared&&p.paramShared.message}),Object(x.jsxs)(qe.a,{component:"fieldset",style:{marginTop:"2%"},children:[Object(x.jsx)(Ve.a,{component:"legend",children:Object(x.jsx)(R.a,{to:"/rules",children:"Track"})}),Object(x.jsx)(He.a,{control:d,name:"task",render:function(e){var t=e.field;return Object(x.jsx)(Ne.a,Object(f.a)(Object(f.a)({row:!0,"aria-label":"position"},t),{},{children:[re[0]].map((function(e,t){return Object(x.jsx)(h.a,{theme:e.theme,children:Object(x.jsx)(Le.a,{value:(t+1).toString(),control:Object(x.jsx)(Be.a,{color:"primary"}),label:Object(x.jsx)(m.a,{color:"primary",children:L(e.name.toLowerCase())}),color:"primary"})})}))}))}})]}),Object(x.jsx)(T.a,{className:e.Button,variant:"contained",color:"primary",type:"submit",disabled:r,children:r?"Submitting...":"Submit"})]})]})}return Object(x.jsx)(j,{})}function st(e){var t=Object(g.a)(),n=new URLSearchParams(Object(c.g)().search),i=Object(a.useState)(n.get("type")||"public"),r=Object(o.a)(i,2),s=r[0],l=r[1],d=function(){switch(s){case"public":return Object(x.jsx)(at,{});case"hidden":return Object(x.jsx)(rt,{});default:return Object(x.jsx)("h1",{children:"No competition type match"})}};return Object(x.jsx)(h.a,{theme:Object(u.a)(ne),children:Object(x.jsxs)(x.Fragment,{children:[Object(x.jsx)(k,{margin:t.spacing(8,"auto",1),children:Object(x.jsx)(we,{title:Object(x.jsx)("span",{children:Object(x.jsx)("strong",{children:"Submission"})}),description:Object(x.jsx)(Ce.a,{format:"YYYY-MM-DD HH:mm:ss",ticking:!0,timezone:"Etc/GMT+12"}),titleColor:"primary"})}),e.login?Object(x.jsxs)(x.Fragment,{children:[Object(x.jsx)($e,{type:s,onTypeChange:function(e){l(e.target.value);var t=new URL(window.location);t.searchParams.set("type",e.target.value),window.history.pushState({},"",t)}}),Object(x.jsx)(d,{})]}):Object(x.jsx)(k,{children:Object(x.jsx)(m.a,{variant:"body1",color:"textSecondary",children:Object(x.jsxs)($,{children:["Please ",Object(x.jsx)(R.a,{to:"/login",children:"login"})," first before submission"]})})})]})})}var ot=Object(d.a)((function(e){return{}}));function ct(e){ot();var t=Object(g.a)(),n=Object(c.h)();return Object(x.jsx)(S,{children:Object(x.jsxs)(c.c,{children:[Object(x.jsxs)(c.a,{path:"".concat(n.path),exact:!0,children:[Object(x.jsxs)(S,{margin:t.spacing(8,"auto",1),children:[Object(x.jsx)(Oe,{title:"Rules",description:Object(x.jsxs)("span",{children:["Submissions are categorized into"," ",Object(x.jsx)($,{children:"three tracks"})," for different usages of the shared pretrained model, and should follow the"," ",Object(x.jsx)(B,{name:"general rules",link:"".concat(n.url,"#general-rules")}),"and the track-specific rules."]})}),Object(x.jsx)(b.a,{container:!0,direction:"row",spacing:4,justify:"center",alignItems:"center",children:re.map((function(e){var a=e.name,i=e.rules,r=(e.submit,e.theme);return Object(x.jsx)(b.a,{item:!0,children:Object(x.jsx)(h.a,{theme:r,children:Object(x.jsxs)("div",{children:[Object(x.jsxs)(m.a,{component:"span",variant:"body1",color:"primary",children:[Object(x.jsx)("strong",{children:L(a.toLowerCase())})," ","track"]}),Object(x.jsx)(p.a,{marginTop:"".concat(t.spacing(1),"px"),children:Object(x.jsx)(N,{buttons:[{name:"rules",link:i?"".concat(n.url,"#").concat(a):null}]})})]})})})}))})]}),Object(x.jsxs)(S,{anchorKey:"general-rules",margin:t.spacing(8,"auto",1),children:[Object(x.jsx)(Oe,{title:"General Rules",description:"The general rules applied to all tracks."}),Object(x.jsxs)(m.a,{variant:"body1",color:"textSecondary",children:[Object(x.jsx)("p",{children:"The rules here apply to all the submissions, including"}),Object(x.jsx)("p",{children:Object(x.jsx)(R.a,{to:"/leaderboard?track=constrained&subset=Paper",children:"SUPERB Benchmark"})}),Object(x.jsx)("p",{children:Object(x.jsx)(R.a,{to:"/leaderboard?track=constrained&subset=Public+Set",children:"SUPERB Challenge Public-set"})}),Object(x.jsx)("p",{children:Object(x.jsx)(R.a,{to:"/leaderboard?track=constrained&subset=Hidden+Dev+Set",children:"SUPERB Challenge Hidden-set"})})]})]}),Object(x.jsxs)(S,{anchorKey:"track-rules",margin:t.spacing(8,"auto",1),children:[Object(x.jsx)(Oe,{title:"Track Rules",description:"The track-specific rules for each of the tracks."}),re.map((function(e){var t=e.name,n=e.rules,a=(e.submit,e.theme);return Object(x.jsx)(h.a,{theme:a,children:Object(x.jsx)(p.a,{maxWidth:650,margin:"auto",children:Object(x.jsxs)(S,{anchorKey:t,children:[Object(x.jsx)(Oe,{title:L(t.toLowerCase()),titleVariant:"h5",titleColor:"primary",divider:!1}),Object(x.jsx)(m.a,{variant:"body1",color:"textSecondary",children:n})]})})})}))]}),Object(x.jsxs)(S,{anchorKey:"download-example",margin:t.spacing(8,"auto",1),children:[Object(x.jsx)(Oe,{title:"Submission example",description:"Download an example of submission."}),Object(x.jsxs)(m.a,{variant:"body1",color:"textSecondary",children:["The prediction output of each task should be put in seperated folder sepified by the task. Finally, please put all the task folders in one folder called ",Object(x.jsx)($,{children:"predict"})," ","and submit a zip archive. You can download an example for submission from this\xa0",Object(x.jsx)(Pe.a,{href:"/api/download/example",color:"secondary",children:"Link"}),"."]})]})]}),re.map((function(e){var t=e.name,a=e.theme;return Object(x.jsx)(c.a,{path:"".concat(n.path,"/").concat(t),children:Object(x.jsx)(h.a,{theme:a,children:Object(x.jsx)(st,Object(f.a)({},e))})})}))]})})}var lt=n(850),dt=n(851),ht=n(855),ut=n(328),pt=n(329),mt=n(351),bt=n(155);function gt(e){return Object(x.jsx)("div",{children:Object(x.jsxs)(S,{children:[Object(x.jsx)(Oe,{title:"Compare",description:"Compare between two submissions including pretraining details and performance."}),Object(x.jsx)(p.a,{display:"flex",alignItems:"center",justifyContent:"center",children:Object(x.jsx)(lt.a,{width:"85%",height:300,children:Object(x.jsxs)(dt.a,{data:[{subject:"Math",A:120,B:110,fullMark:150},{subject:"Chinese",A:98,B:130,fullMark:150},{subject:"English",A:86,B:130,fullMark:150},{subject:"Geography",A:99,B:100,fullMark:150},{subject:"Physics",A:85,B:90,fullMark:150},{subject:"History",A:65,B:85,fullMark:150}],children:[Object(x.jsx)(ht.a,{}),Object(x.jsx)(ut.a,{dataKey:"subject"}),Object(x.jsx)(pt.a,{angle:30,domain:[0,150]}),Object(x.jsx)(mt.a,{name:"Mike",dataKey:"A",stroke:"#8884d8",fill:"#8884d8",fillOpacity:.6}),Object(x.jsx)(mt.a,{name:"Lily",dataKey:"B",stroke:"#82ca9d",fill:"#82ca9d",fillOpacity:.6}),Object(x.jsx)(bt.a,{})]})})})]})})}var jt,ft=n(16),Ot=n(27),wt=n(132),xt=n(190),vt=n(80),St=n(189),yt=n(191),kt=n.n(yt),_t=n(192),Tt=n.n(_t),At=n(150),Rt=n.n(At),Pt=n(876),Et=n(856),Ct=n(787),Bt=n(857),Nt=Object(d.a)((function(e){return{modal:{display:"flex",alignItems:"center",justifyContent:"center"}}}));function Lt(e){var t=e.tableInstance,n=e.modalOpenRef,a=void 0===n?null:n,r=Nt(),s=i.a.useState(!1),c=Object(o.a)(s,2),l=c[0],d=c[1],h=t.allColumns,u=(t.setGlobalFilter,function(){d(!0)}),j=Object(g.a)();return Object(x.jsxs)("div",{children:[a?Object(x.jsx)("div",{ref:a,onClick:u}):Object(x.jsx)("button",{type:"button",onClick:u,children:"react-transition-group"}),Object(x.jsx)(Pt.a,{"aria-labelledby":"transition-modal-title","aria-describedby":"transition-modal-description",className:r.modal,open:l,onClose:function(){d(!1)},closeAfterTransition:!0,BackdropComponent:Et.a,BackdropProps:{timeout:500},children:Object(x.jsx)(Ct.a,{in:l,children:Object(x.jsx)(p.a,{width:"85%",maxWidth:700,children:Object(x.jsx)(_e.a,{children:Object(x.jsxs)(p.a,{padding:j.spacing(4,6),margin:"auto",maxHeight:"80vh",overflow:"auto",children:[Object(x.jsxs)(y,{children:[Object(x.jsx)(we,{title:"Leaderboard"}),Object(x.jsxs)(m.a,{variant:"body2",color:"textSecondary",children:["All the submissions are presented in a single table. You can use the buttons below to choose which tracks you are interested or what information (column) you wish to compare. The default ranking of all submissions are sorted by a randomly selected task, so the ranking will be different everytime you refresh the page. You can check the column with the"," ",Object(x.jsx)("span",{style:{color:J.a[300]},children:"green task name"})," ","for the current sorting column."]})]}),Object(x.jsxs)(y,{children:[Object(x.jsx)(we,{title:"Toggles"}),Object(x.jsx)(p.a,{margin:j.spacing(4,"auto",0),children:Object(x.jsx)(b.a,{container:!0,direction:"row",children:h.map((function(e){return Object(x.jsx)(b.a,{item:!0,xs:12,sm:6,md:4,lg:3,children:Object(x.jsx)(Le.a,{control:Object(x.jsx)(Bt.a,{checked:e.isVisible,onChange:function(){e.toggleHidden()},name:e.Header}),label:e.Header})})}))})})]})]})})})})})]})}function $t(e){var t=e.task,n=e.onTaskChange,a=function(e){var t=e.toLowerCase();return"less-constrained"===t?"Less.":"unconstrained"===t?"Un.":"constrained"===t?"Const.":"all"===t?"All":e};return Object(x.jsx)("div",{className:"select group",style:{width:"fit-content",maxWidth:"100%",margin:"5px auto"},children:Object(x.jsxs)(qe.a,{component:"fieldset",children:[Object(x.jsx)(E,{link:"rules",children:Object(x.jsx)("span",{style:{color:"#4697E1",textDecoration:"underline",textDecorationThickness:.5},children:"Tracks"})}),Object(x.jsx)(Ne.a,{row:!0,"aria-label":"position",name:"position",defaultValue:"constrained",value:t,onChange:n,children:se.map((function(e){return Object(x.jsx)(h.a,{theme:e.theme,children:Object(x.jsx)(Le.a,{value:e.name,control:Object(x.jsx)(Be.a,{color:"primary"}),label:Object(x.jsx)(m.a,{color:"primary",children:a(e.name)}),color:"primary"})})}))})]})})}function It(e){var t=e.subset,n=e.selections,a=e.onChange,i=function(e){var t=e.toLowerCase();return"paper"===t?"Paper":"public set"===t?"Challenge Public":"hidden dev set"===t?"Challenge Hidden Dev":e};return Object(x.jsx)("div",{className:"select group",style:{width:"fit-content",maxWidth:"100%",margin:"10px auto"},children:Object(x.jsxs)(qe.a,{component:"fieldset",children:[Object(x.jsx)("span",{style:{color:"#4697E1"},children:"Task Collections"}),Object(x.jsx)(Ne.a,{row:!0,"aria-label":"position",name:"position",defaultValue:"Public Set",value:t,onChange:a,children:n.map((function(e){return Object(x.jsx)(Le.a,{value:e,control:Object(x.jsx)(Be.a,{color:"textPrimary"}),label:Object(x.jsx)(m.a,{color:"textPrimary",children:i(e)}),color:"primary"})}))})]})})}function Dt(e,t,n){return e<=t?e:(e-t)/Math.max(n+1e-12,1)}function zt(e){for(var t=Object.keys(e[0]),n=e.map((function(e){return{}})),a=function(a){var i=t[a],r=e.map((function(e){return e[i]}));(r=r.filter((function(e){return I(e)}))).sort((function(e,t){return e-t}));for(var s=0;s<e.length;s++){var o=e[s][i];I(o)?n[s][i]=r.indexOf(o):n[s][i]=0}},i=0;i<t.length;i++)a(i);return n}function Ht(e){var t,n=Object.keys(e[0]),a=new Set(n.map((function(e){return e.split("_")[0]}))),i=e.map((function(e){return{}})),r=Object(Ot.a)(a.values());try{var s=function(){for(var a=t.value,r=n.filter((function(e){return e.split("_")[0]==a})),s=function(t){var n=e[t],s=r.map((function(e){return n[e]})).reduce((function(e,t){return e+t}),0)/r.length;i[t][a]=s},o=0;o<e.length;o++)s(o)};for(r.s();!(t=r.n()).done;)s()}catch(o){r.e(o)}finally{r.f()}return i.map((function(e){return Object.values(e).reduce((function(e,t){return e+t}),0)/Array.from(a).length}))}function Ft(e,t,n,a,i){var r,s=t.filter((function(e){return!e.isScore})),c=t.filter((function(e){return e.isScore}));if("Paper"===a?c=c.filter((function(e){return["PR_per_public","SID_acc_public","KS_acc_public","QbE_mtwv_public","IC_acc_public","ASR_wer_public","SV_eer_public","ER_acc_public","SD_der_public","SF_cer_public","SF_f1_public"].includes(e.accessor)})):"Public Set"===a?c=c.filter((function(e){return["PR_per_public","SID_acc_public","QbE_mtwv_public","ASR_wer_public","SV_eer_public","ER_acc_public","SD_der_public","ST_bleu_public","SE_pesq_public","SE_stoi_public","SS_sisdri_public"].includes(e.accessor)})):"Hidden Dev Set"===a?c=c.filter((function(e){return be.includes(e.accessor)})):"Hidden Test Set"===a&&(c=c.filter((function(e){return ge.includes(e.Header)}))),n.length>0){var l=function(e,t){for(var n=[],a=0;a<t.length;a++){for(var i={},r=0;r<e.length;r++){var s=e[r].accessor,o=t[a][s];s.includes("ERfold")||s.includes("ASR_LM")||(s.includes("_eer_")||s.includes("_per_")||s.includes("_wer_")||s.includes("_der_")||s.includes("_cer_")?i[s]=100-o:i[s]=o)}n.push(i)}return n}(c,n),d=n.map((function(e){return parseFloat(e.paramShared)/1e6})),h=function(e){for(var t=Object.keys(e[0]),n=e.map((function(e){return{}})),a=0;a<t.length;a++){var i,r,s=t[a],c=me[s];if(void 0!=c){var l=Object(o.a)(c,2);r=l[0],i=l[1];for(var d=0;d<e.length;d++){var h=e[d][s];I(h)?n[d][s]=1e3/(i-r+1e-12)*(h-r):n[d][s]=void 0}}else console.log("No reference points defined. Cannot calculate metric for ".concat(s,"."))}return n}(l),u=function(e,t){for(var n=e.map((function(e){return{}})),a=0;a<e.length;a++){var i=e[a],r=t[a];for(var s in i)n[a][s]=Dt(e[a][s],0,r)}return n}(h,d);if(e.includes("interpolation_p")){for(var p=Ht(u),m=0;m<n.length;m++)n[m].score_p=parseFloat(p[m].toFixed(2));c.unshift({Header:"Score-P",accessor:"score_p",width:90,sortType:i,higherBetter:!0,isScore:!0,Cell:function(e){var t=e.value;return I(t)?String(Math.round(100*t)/100):"-"}})}if(e.includes("rank_p")){for(var b=Ht(zt(u)),g=0;g<n.length;g++)n[g].rank_p=b[g];c.unshift({Header:"Rank-P",accessor:"rank_p",width:90,sortType:i,higherBetter:!0,isScore:!0,Cell:function(e){var t=e.value;return I(t)?String(Math.round(100*t)/100):"-"}})}if(e.includes("interpolation")){for(var j=Ht(h),O=0;O<n.length;O++)n[O].score=Math.round(j[O]);c.unshift({Header:"Score",accessor:"score",width:80,sortType:i,higherBetter:!0,isScore:!0,Cell:function(e){var t=e.value;return I(t)?String(Math.round(100*t)/100):"-"}})}if(e.includes("rank")){for(var w=Ht(zt(h)),x=0;x<n.length;x++)n[x].rank=w[x];c.unshift({Header:"Rank",accessor:"rank",width:80,sortType:i,higherBetter:!0,isScore:!0,Cell:function(e){var t=e.value;return I(t)?String(Math.round(100*t)/100):"-"}})}r=[];for(var v=0;v<n.length;v++)if("FBANK"!=n[v].submitName){var S=Object(f.a)({},n[v]);r.push(S)}}return void 0!=r&&(n=r),s.push.apply(s,Object(ft.a)(c)),[s,n]}var Ut=xt.a.div(jt||(jt=Object(wt.a)(["\n  .table {\n    outline: 1px solid #ddd;\n    \n    .th,\n    .td {\n      background-color: ",";\n      overflow: hidden;\n      white-space: nowrap;\n      text-overflow: ellipsis;\n      border: 0.2px solid #ddd;\n      padding: ",";\n    }\n\n    .th {\n      font-weight: bold;\n      padding: ",";\n    }\n\n    .toggle {\n      display: flex;\n      align-items: center;\n      justify-content: center;\n    }\n\n    &.sticky {\n      overflow: scroll;\n      .header,\n      .footer {\n        position: sticky;\n        z-index: 1;\n        width: fit-content;\n      }\n\n      .header {\n        top: 0;\n        box-shadow: 0px 3px 3px #ccc;\n      }\n\n      .footer {\n        bottom: 0;\n        box-shadow: 0px -3px 3px #ccc;\n      }\n\n      .body {\n        position: relative;\n        z-index: 0;\n      }\n\n      [data-sticky-td] {\n        position: sticky;\n      }\n\n      [data-sticky-last-left-td] {\n        box-shadow: 2px 2px 3px #ccc;\n      }\n\n      [data-sticky-first-right-td] {\n        box-shadow: -2px -2px 3px #ccc;\n      }\n    }\n  }\n\n  .resizer {\n    display: inline-block;\n    background: ",";\n    width: ",";\n    height: 100%;\n    position: absolute;\n    right: 0;\n    top: 0;\n    transform: translateX(50%);\n    z-index: 1;\n    ","\n    touch-action:none;\n\n    &.isResizing, &:hover {\n      background: ",";\n    }\n"])),(function(e){return e.theme.palette.primary.main}),(function(e){return e.theme.spacing(1,1)}),(function(e){return e.theme.spacing(1.5,1)}),(function(e){return"".concat(Object(_.b)(e.theme.palette.text.primary,.2))}),(function(e){return"".concat(e.theme.spacing(2),"px")}),"",(function(e){return"".concat(Object(_.b)(e.theme.palette.text.primary,.6))}));function Wt(e){var t=e.columns,n=e.data,a=e.height,r=void 0===a?"500px":a,s=e.tableControlRef,o=void 0===s?null:s,c=Object(g.a)(),l=i.a.useMemo((function(){return{minWidth:10,width:150,maxWidth:400}}),[]),d=t.filter((function(e){return e.isScore})),h=(d[Math.floor(Math.random()*d.length)],i.a.useMemo((function(){return[{id:"rank",desc:!0}]}))),u=Object(vt.useTable)({columns:t,data:n,defaultColumn:l,initialState:{hiddenColumns:["aoeTimeUpload","task","stride","inputFormat","corpus","paramDesc","paramShared","fineTunedParam","taskSpecParam"],sortBy:h}},vt.useSortBy,vt.useBlockLayout,vt.useResizeColumns,St.useSticky),p=u.getTableProps,m=u.getTableBodyProps,b=u.headerGroups,j=u.rows,O=u.prepareRow;return Object(x.jsxs)(Ut,{theme:c,children:[Object(x.jsx)(Lt,{tableInstance:u,modalOpenRef:o}),Object(x.jsxs)("div",Object(f.a)(Object(f.a)({},p()),{},{className:"table sticky",style:{width:"fit-content",maxWidth:"100%",maxHeight:r,margin:"auto"},children:[Object(x.jsx)("div",{className:"header",children:b.map((function(e){return Object(x.jsx)("div",Object(f.a)(Object(f.a)({},e.getHeaderGroupProps()),{},{className:"tr",children:e.headers.map((function(e){var t=void 0==e.isSortedDesc||void 0==e.higherBetter?c.palette.text.primary:e.isSortedDesc==e.higherBetter?J.a[300]:Y.a[300];return Object(x.jsxs)("div",Object(f.a)(Object(f.a)({},e.getHeaderProps()),{},{className:"th",children:[Object(x.jsxs)("div",Object(f.a)(Object(f.a)({},e.getSortByToggleProps()),{},{className:"toggle",children:[Object(x.jsx)("span",{style:{margin:"0px 1px",color:t},children:e.render("Header")}),void 0!=e.higherBetter&&(e.higherBetter?Object(x.jsx)(kt.a,{style:{fontSize:16,color:t}}):Object(x.jsx)(Tt.a,{style:{fontSize:16,color:t}}))]})),Object(x.jsx)("div",Object(f.a)(Object(f.a)({},e.getResizerProps()),{},{className:"resizer ".concat(e.isResizing?"isResizing":"")}))]}))}))}))}))}),Object(x.jsx)("div",Object(f.a)(Object(f.a)({},m()),{},{className:"body",children:j.map((function(e,t){return O(e),Object(x.jsx)("div",Object(f.a)(Object(f.a)({},e.getRowProps()),{},{className:"tr",children:e.cells.map((function(e){return Object(x.jsx)("div",Object(f.a)(Object(f.a)({},e.getCellProps()),{},{className:"td",children:e.render("Cell")}))}))}))}))}))]}))]})}var Mt,qt=function(e){var t=new URLSearchParams(Object(c.g)().search),n=Object(a.useContext)(Ye),r=Object(g.a)(),s=Object(a.useState)([]),l=Object(o.a)(s,2),d=l[0],h=l[1],u=Object(a.useState)([]),m=Object(o.a)(u,2),b=m[0],j=m[1],O=Object(a.useState)([]),w=Object(o.a)(O,2),v=w[0],S=w[1],y=Object(a.useState)([]),k=Object(o.a)(y,2),_=k[0],T=k[1],R=Object(a.useState)(t.get("track")||"constrained"),P=Object(o.a)(R,2),E=P[0],C=P[1],B=Object(a.useState)(t.get("subset")||"Paper"),N=Object(o.a)(B,2),L=N[0],$=N[1],z=L.toLowerCase().includes("hidden")?"hidden":"public",H=i.a.useCallback(D),F={CONSTRAINED:"constrained",LESS_CONSTRAINED:"less-constrained",UNCONSTRAINED:"unconstrained"},U=function(){var e=Object(ze.a)(De.a.mark((function e(){return De.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return e.next=2,Me.a.get("/api/submission/leaderboard").then((function(e){h(e.data.leaderboard),j(e.data.leaderboard.filter((function(e){return F[e.task]===E})))})).catch((function(e){console.error(e)}));case 2:return e.next=4,Me()({method:"get",url:"/api/hiddensubmission/leaderboard"}).then((function(e){var t=e.data.leaderboard;if((t=t.filter((function(e){return function(e){var t,n=Object(Ot.a)(be);try{for(n.s();!(t=n.n()).done;)if(!I(e[t.value]))return!1}catch(a){n.e(a)}finally{n.f()}return!0}(e)}))).length>0){var a,i=[],r=new Set(t.map((function(e){return e.name}))),s=Object(Ot.a)(r);try{var o=function(){var e=a.value,r=t.filter((function(t){return t.name===e}));if(r.length<1)return"continue";if(e.includes("baseline"))return i.push.apply(i,Object(ft.a)(r)),"continue";var s,o=n.email,c=Object(Ot.a)(r);try{for(c.s();!(s=c.n()).done;){var l=s.value;l.email!=o&&(l.name="-",l.submitName="-",l.modelDesc="-")}}catch(d){c.e(d)}finally{c.f()}r.reduce((function(e,t){return"YES"===e.showOnLeaderboard||"YES"===t.showOnLeaderboard}),{showOnLeaderboard:!1})?i.push.apply(i,Object(ft.a)(r.filter((function(e){return e.showOnLeaderboard})))):i.push.apply(i,Object(ft.a)(r))};for(s.s();!(a=s.n()).done;)o()}catch(c){s.e(c)}finally{s.f()}S(i),T(i)}})).catch((function(e){console.error(e)}));case 4:case"end":return e.stop()}}),e)})));return function(){return e.apply(this,arguments)}}(),W=function(e){var t=e.value;return"-"===t?String(t):Object(x.jsx)("a",{href:t,children:Object(x.jsx)(Rt.a,{style:{height:"20px"}})})};Object(a.useEffect)((function(){U()}),[]);var M="hidden"==z?pe:ue,q=Object.keys(M).map((function(e){var t=M[e].isScore;return{Header:M[e].header,accessor:e,width:M[e].width,sortType:M[e].isScore?H:"alphanumeric",higherBetter:M[e].higherBetter,isScore:t,Cell:"modelURL"===e?W:function(e){var n=e.value;return t?I(n)?String(Math.round(100*n)/100):"-":void 0==n?"-":String(n)}}}));q[0].sticky="left";var V,Y,Q=Ft(["rank","rank_p","interpolation","interpolation_p"],q,"hidden"==z?_:b,L,H),J=Object(o.a)(Q,2);V=J[0],Y=J[1];var K=i.a.useMemo((function(){return V}));return Object(x.jsxs)(x.Fragment,{children:[Object(x.jsxs)(p.a,{width:"90%",margin:"auto",children:[Object(x.jsx)(p.a,{margin:r.spacing(2,"auto",.2),children:Object(x.jsx)($t,{task:E,onTaskChange:function(e){C(e.target.value);var t=new URL(window.location);t.searchParams.set("track",e.target.value),window.history.pushState({},"",t);var n="hidden"===z?T:j,a="hidden"===z?v:d;"all"===e.target.value?n(a):n(a.filter((function(t){return F[t.task]===e.target.value})))}})}),Object(x.jsx)(A.a,{style:{width:"600px",maxWidth:"80%",margin:"auto"}}),Object(x.jsx)(p.a,{margin:r.spacing(.2,"auto",1),children:Object(x.jsx)(It,{subset:L,selections:["Paper","Public Set","Hidden Dev Set"],onChange:function(e){$(e.target.value);var t=new URL(window.location);t.searchParams.set("subset",e.target.value),window.history.pushState({},"",t)}})})]}),Object(x.jsx)(Wt,Object(f.a)({columns:K,data:Y},e))]})},Vt=n(345),Yt=n(350),Qt=n(347),Jt=n(346),Kt=n(873),Gt=n(858),Xt=String.raw(Mt||(Mt=Object(wt.a)(['\n# SUPERB Challenge\n\n## Evaluation Framework\n\n### Background\n\n![](https://i.imgur.com/FDARwvz.png)\n*Fig 1.*\n\nSUPERB Challenge follows the similar evaluation framework introduced in [SUPERB Benchmark](https://arxiv.org/abs/2105.01051), which benchmarks the **generalizability** of Self-Supervised Learning (SSL) on speech. SSL models are termed **Upstream** and are evaluated with various **Downstream** tasks. The framework extract **multiple frozen hidden states** from a single upstream model and trains a learnable **weighted-sum** over the hidden states along with the downstream model task-by-task.\n\n### Overview\n\n![](https://i.imgur.com/BNr2gfE.png)\n*Fig 2.*\n\nFig 2. illustrates the evaluation framework of the challenge. The challenge evaluates SSL models\' generalizability on 10 tasks. Each of the tasks has a corresponding public dataset (**public-set**) that is publicly available, and a hidden dataset (**hidden-set**) that will not be released. Participants can practice on the public-set to understand the performance of their upstream models, and choose the best one for submission as they wish. Then, participants **submit the upstream model** (model definition & pre-trained weights) publicly or privately to the hidden-set leaderboard. **We finetune the downstream models on the hidden-set** without releasing any audio/label. Both public-set and hidden-set have leaderboards and welcome submissions to share more results with the community. **The winners of the challenge will be solely determined by the ranking on the hidden-set leaderboard.** Finally, there will be **overall metrics** for ranking all upstreams.\n\nAll the participants are encouraged to submit papers to [*AAAI workshop: The 2nd Self-supervised Learning for Audio and Speech Processing*](https://aaai-sas-2022.github.io/). The winners of the challenge will be invited to present their methods in the workshop. We plan to collaborate with more conferences for participants to present their works and papers.\n\n### Tasks\n\n10 evaluation tasks are included in this challenge:\n\n- **Content**\n    - Phoneme Recognition (PR)\n    - Automatic Speech Recognition (ASR)\n    - Query-by-example Spoken Term Detection (QbE)\n- **Speaker**\n    - Speaker Identification (SID)\n    - Automatic Speaker Verification (ASV)\n    - Speaker Diarization (SD)\n- **Paralinguistics**\n    - Emotion Recognition (ER)\n- **Semantics**\n    - Speech Translation (ST)\n- **Generation**\n    - Speech Enhancement (SE)\n    - Speech Separation (SS)\n\nMore task descriptions for the public-set can be found in [TASKS](https://superbbenchmark.org/tasks), and we implement the evaluation scripts for public-set in [S3PRL](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/docs/superb.md) for reference. The task design and evaluation pipeline will be the same between public-set & hidden-set unless otherwise mentioned.\n\n### Secret tasks\n\nSecret tasks evaluate SSL models\' generalizability on completely unseen tasks. Secret tasks are only present in the hidden-set, and the task design will not be revealed until the final winner announcement. \n\n### What is new\n\nCompared with SUPERB Benchmark, SUPERB Challenge extends the framework with the following:\n\n- **New Tasks**: Speech Translation, Speech Enhancement, Source Separation and secret tasks.\n- **New Data Domains**: A challenging and newly recorded hidden-set with unseen (to upstream) text/audio domain.\n- **New Overall Metrics**: The metrics to rank upstreams.\n\n\n## Upstream Specification\n\n### Unlabeled data only: Focus on SSL\n\n- Any labeled/parallel data made by human annotators are **not allowed** to used for both model training and data preprocessing, e.g.\n    - **audio/text pairs:** transcriptions in English, foreign languages, or phonemes.\n    - **audio/tagging pairs:** speaker labels or sound event labels.\n    - **audio/audio pairs:** audios with the same properties made parallel by human, e.g. audios with same content from different speakers, or the opposite.\n- Any system pre-trained by labeled/parallel data **cannot** be used to help with the SSL pre-training, like pre-trained ASR.\n- Any unlabeled/unparallel data is allowed, including the downstream datasets in the public-set. The nature alignments (not made by human annotators) bettwen audio and other modalities are also allowed, e.g. videos.\n- If it is hard to define whether your data is labeled/parallel, please [contact us](#Contact)!\n\n### Programming Language\n\n- We currently support:\n    - **Python >= 3.6**\n    - **Pytorch >= 1.7**\n\n- We expect the upstream submission can pass the following check:\n    ~~~python=\n    upstream = YourModel.cuda()\n    assert isinstance(upstream, torch.nn.Module)\n    ~~~\n\n\nWe accept upstream models in PyTorch by default. If you wish to submit upstreams in non-PyTorch frameworks, please [fill this form](https://docs.google.com/forms/d/e/1FAIpQLSe52jYL2Yk9oYqXfg_Bg0Sjp01a6HSLUhY5VohsZOE5sNmgsw/viewform)!\nIf you are not feasible to submit the pre-trained model, please [fill this form](https://docs.google.com/forms/d/e/1FAIpQLSdA44nArlIDfGV63WwtwXer4WAPQO1aBwEpAjDSNjbMQN-GJQ/viewform) for us to see how to help!\n\n### Interface functions\n\n#### forward\n\nExtract features from waveforms.\n\n- **Input:** A list of waveforms in 16000 Hz\n\n    ~~~python=\n    SAMPLE_RATE = 16000\n    BATCH_SIZE = 8\n    EXAMPLE_SEC = 10\n    wavs = [torch.randn(SAMPLE_RATE * EXAMPLE_SEC).cuda() for _ in range(BATCH_SIZE)]\n    results = upstream(wavs)\n    ~~~\n\n- **Output:** A dictionary with a key for each task, and a single key for all secret tasks. If any task-specific key is not presented, a "hidden_states" key should be provided as the default key. The value for each key is **a list** of padded sequences in the same shape of **(batch_size, max_sequence_length_of_batch, hidden_size)** for weighted-sum to work. It is welcomed to perform some preprocessing on the upstream\'s raw hidden-sets, including upsampling and downsampling. However, all the values must come from **a single upstream model**:\n\n    ~~~python=\n    assert isinstance(results, dict)\n    tasks = ["PR", "SID", "ER", "ASR", "ASV", "SD", "QbE", "ST", "SS", "SE", "secret"]\n    for task in tasks:\n        hidden_states = results.get(task, "hidden_states")\n        assert isinstance(hidden_states, list)\n\n        for state in hidden_states:\n            assert isinstance(state, torch.Tensor)\n            assert state.dim() == 3, "(batch_size, max_sequence_length_of_batch, hidden_size)"\n            assert state.shape == hidden_states[0].shape\n    ~~~\n\n#### get_downsample_rates\n\nProvide the downsample rate **from 16000 Hz waveforms** for each task\'s representation in the dict. For the standard 10ms stride representation, the downsample rate is 160.\n\n~~~python=\nSAMPLE_RATE = 16000\nMSEC_PER_SEC = 1000\ndownsample_rate = SAMPLE_RATE * 10 / MSEC_PER_SEC  # 160\n~~~\n\nThe downsample rate will be used to:\n\n1. Calculate the valid representation length of each utterance in the output padded representation.\n2. Prepare the training materials according to the representation\'s downsample rate for frame-level tasks: SD, SE, SS.\n\n- **Input:** the task key (str)\n- **Output:** the downsample rate (int) of the representation for that task\n\n~~~python=\nfor task in tasks:\n    assert isinstance(task, str)\n    downsample_rate = upstream.get_downsample_rate(task)\n    assert isinstance(downsample_rate, int)\n    print("The upstream\'s representation for {task}"\n        f" has the downsample rate of {downsample_rate}.")\n~~~\n\n## Public-set and S3PRL toolkit\n\n### As the task definition and demonstration\n\nThe public-set serves as the demonstration of the task design: including the data preprocessing, tasks\' input/output formats and task-specific metrics. The datasets used in the public-set are all chosen to be public available for everyone to participate. Please refer to [TASKS](https://superbbenchmark.org/tasks) and the implementation in [S3PRL](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/docs/superb.md) for details.\n\n### As the platform for developing upstreams for the hidden-set\n\nThe differences between the public-set and the hidden-set are controlled to be only the following:\n\n1. Recording conditions\n2. Spoken content / text scripts\n3. Speakers\n4. Fewer labeled data\n\nIn this way, the public-set is still a good indicator of the hidden-set performance to some degree. We follow the same (unless mentioned otherwise in [TASKS](/tasks)) implementation in the public-set for the hidden-set, and hence encourage participants to use [S3PRL](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/docs/superb.md) to benchmark their upstream models (optional) on the public-set. The winners of the challenge will be decided solely on the hidden-set, and the public-set and [S3PRL](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/docs/superb.md) implementations can serve as the start-kit.\n\n### Provide baselines for comparison\n\n#### Baselines\n\nWe collected most of the well-known SSL baseline models in [S3PRL](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/docs/superb.md), including TERA, wav2vec2, Hubert, DeCoAR 2.0, and more. You can easily benchmark different upstreams by specifying in the command line arguments.\n\n#### Comparison\n\nSince the full benchmarking on the public-set can take some time for the training to converge. We released the [training artifacts](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/docs/superb_artifacts.md) of the top baseline systems (e.g. wav2vec2, HuBERT) for participants to quickly compare with them. The artifacts include:\n\n- Tensorboard logs\n- Trained downstream weights (the best on public dev set)\n\n### Public-set leaderboard and submission\n\nThe [public-set leaderboard](leaderboard?subset=Public+Set&track=constrained) is online and [accepts submissions](submit?type=public). There is no deadline. Since all the train/dev/test splits are public available, **the leaderboard accepts submissions with the inferenced prediction files on each task\'s testing split** which will be auto-generated if you follow the benchmarking steps in [S3PRL](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/docs/superb.md).\n\n## Hidden-set\n\n### Fairness & prevent overfitting\n\nSince all the train/dev/test splits are public in the public-set, it is possible to cheat by directly reporting the best results on the testing split, and the results are thus overfit on the testing split. Hence, the hidden-set is collected and prepared to follow the same task design as that in the public-set but with the newly created data. All the splits will **NOT be released in both audio and labels**. The members involved in the hidden-set preparation should **NOT** participate the challenge. These members are listed in the **Hidden-set Committee** below.\n\n### Hidden-set leaderboard and submission\n\n#### Submission type\n\nThe leaderboard accepts **submissions with the upstream model solely**, including **model definition** and **pre-trained weights**. The upstream model should follow the specification detailed at [Upstream Specification](#Upstream-Specification). The submission can be done publicly or privately. Only the **Hidden-set Committee** members can access the privately submitted upstreams and the models will be used solely for this challenge.\n\n- We accept upstream models in PyTorch by default. If you wish to submit upstreams in non-PyTorch frameworks, please [fill this form](https://docs.google.com/forms/d/e/1FAIpQLSe52jYL2Yk9oYqXfg_Bg0Sjp01a6HSLUhY5VohsZOE5sNmgsw/viewform)!\n- If you are not feasible to submit the pre-trained model, please [fill this form](https://docs.google.com/forms/d/e/1FAIpQLSdA44nArlIDfGV63WwtwXer4WAPQO1aBwEpAjDSNjbMQN-GJQ/viewform) for us to see how to help!\n\n#### Finetuning on submission\n\nAfter the upstream model is submitted, we **benchmark the submitted upstream by finetuning each task\'s downstream model for participants**. **The quota for submissions per week is limited and starts from 2 times/week,** but will be dynamically adjusted based on the number of participants. The quota adjustment will be announced at [NEWS](https://superbbenchmark.org/news). Participants can [contact us](#Contact) to acquire the finetuning artifacts of their own submissions for sanity checks, including:\n\n- Tensorboard logs\n- Testing results\n- Trained downstream weights\n\n#### Practice (dev) / Private (test) scores\n\nAfter training the downstream model for all tasks, we show the best performance on the hidden-set\'s development splits as the **practice scores** (one score per task). The true performance on the testing splits, termed **private scores**, will be revealed along with the final winner announcement. The final team ranking will depend only on the hidden-set\'s **private scores**.\n\n#### How to submit\n\n(Update 10/20/2021 AOE)\n\nThe [hidden-set leaderboard](leaderboard?subset=Hidden+Dev+Set&track=constrained) is online and accepts submissions. Please follow [the submission steps](https://huggingface.co/superb/superb-submission). We use HuggingFace\'s Hub to host the submitted upstreams and track the submitted model weights. On the other hand, we use our [submission page](submit?type=hidden) to control the submission limit, where the participants tell us the locations of their models on HuggingFace\'s Hub.\n\nAfter submitting via the submission page, you will see a new entry in the **submission history** under your Profile page, and the evaluation results on the hidden-set will be revealed at the entry within one week.\nPlease stay tuned!\n\n(Update 10/31/2021 AOE)\n\nAll the submitted results will remain anonymous during and after the challenge.\nYou can select a few submissions to show on the leaderboard.\nIf no submission is selected, we will show all your submissions on the leaderboard anonymously.\nOnly you can see your personal/model information on the leaderboard, but you will not see others\'.\nIf you wish to reveal your personal/model information on the [hidden-set leaderboard](leaderboard?subset=Hidden+Dev+Set&track=constrained), please [contact us](#Contact)!\n\n## Overall Metrics\n\n(Update 10/1/2021 AOE)\n\nWe announce two kinds of metrics: **superb-rank** and **superb-score**, each with parameter-agnostic and parameter-panelized versions.\n\nType|Parameter-agnostic|Parameter-penalized\n-|-|-\nScoring|$superb_s$|$superb_{sp}$\nRanking|$superb_r$|$superb_{rp}$\n\nIn this challenge, $superb_r$ and $superb_{rp}$ are the primary metrics. When equal rank is found on two different upstreams, $superb_{s}$ or $superb_{sp}$ is used to break the tie. Hence, there will be only two final lists of winners: **Parameter-agnostic** and **Parameter-penalized**.\n\n### Notation\n\nSuppose each task $t$ in all tasks $T$ has a single metric $s_t$, and the score of an upstream $u$ on task $t$ is $s_t(u)$ which has already been transformed to make higher values represent better performance. Eg. We use WAcc here for ASR instead of the raw WER. The upstream $u$ has $|u|$ millions parameters.\n\n### Parameter-agnostic\n\nParameter-agnostic metrics demonstrate the best performance SSL can achieve, and encourages participants to explore any possibility to push the limits.\n\n#### $superb_s$\n\nTo aggregate all task-specific scores $s_t(u)$ into a single static score, we linearly transform each of them into points so that:\n\n- $s_t(fbank) = 0$, The performance of FBANK maps to 0\n- $s_t(sota) = 1000$, The performance of the existing SOTA upstream *for this task* maps to 1000.\n\n$$\np_t(u) = dfrac{1000}{s_t({sota}) - s_t({fbank})} ( s_t(u) - s_t({fbank}) )\n$$\n\nHence, most of the points will sit between 0~1000. The upstream worse than FBANK on this task will get negative points. The upstream better than the task-specific SOTA upstream will get points higher than 1000. The $superb_s$ of the upstream $u$ is the average of $p_t$ over all tasks.\n\n$$\nsuperb_s = dfrac{1}{|T|} sum_{t in T} p_t(u)\n$$\n\nIntuitively, two reference points: FBANK and SOTA decide the typical interested interval for a task-specific metric and scale the task scores to 0~1000 points accordingly. The similar range of points across tasks can then be averaged. Beyond scaling with the pre-defined metric range, this interval further determines *how hard for a task to improve*. For a harder task, its smaller interval at the denominator give the task more credit for any unit improvement.\n\n#### $superb_r$\n\nTo encourage the development on **universal models** instead of models skewed toward a subset of tasks. We use ranking to saturate the improvement when an upstream already become the best for that task. The $superb_r$ for an upstream $u$ is the average number of upstreams which $u$ can win in each task. This metric dynamically depends on all the upsreams $U$ shown on the leaderboard. In the following, $L$ is the number of upstreams which $u$ can win using the metric $x_t$.\n\n$$\nL(x_t, u) = | { hat{u} in U | x_t(u) > x_t(hat{u})  } |\n$$\n\n$$\nsuperb_r = dfrac{1}{|T|} sum_{t in T} L(s_t, u) = dfrac{1}{|T|} sum_{t in T} L(p_t, u)\n$$\n\n### Parameter-penalized\n\nTo encourage the development of speech SSL on small and green models, we add a metric with penalization on models\' parameter size. To gauge the effectiveness and parameter-efficiency of new SSL algorithms, we encourage participants to submit multiple upstreams trained by the same algorithm with the only difference in parameter size.\n\n#### $superb_{sp}$\n\nWe penalize the parameter-agnostic scoring by an upstream $u$\'s parameter size $|u|$.\n\n$$\nhat{p_t}(u) =\nleft{\n    \begin{array}{lr}\n        \frac{p_t(u)}{ max(|u|, 1)},& \text{if } p_t(u) geq 0\\\n            p_t(u),              & \text{otherwise}\n    end{array}\n\right.\n$$\n\nSince either the point of the baseline FBANK or its parameter size is 0. The above formula measures how many improvement upon FBANK per parameter. The minimum 1 million parameter size is designed to avoid too small upstreams dominating others by receiving too much credit on a single task. When $p_t(u)$ is negative we do not penalize it, since it is already worse than the zero-parameter FBANK.\n\n$$\nsuperb_{sp} = dfrac{1}{|T|} sum_{t in T} hat{p_t}(u)\n$$\n\n#### $superb_{sp}$\n\nSimilar to $superb_r$, we rank all upstreams on the leaderboard with $hat{p_t}$.\n\n$$\nsuperb_{rp} = dfrac{1}{|T|} sum_{t in T} L(hat{p_t}, u)\n$$\n\n### Conclusion\n\nThe ranking metrics are the primary measures in this challenge and are designed to emphasize an upstream\'s universally usability. When two upstreams tie on the same rank, the scoring metrics take the tasks\' variations and improvement difficulty into account to help the final decision. You can refer to the [public-set leaderboard](leaderboard?subset=Public+Set&track=constrained) for the overal metrics calculation.\n\n#### Reference points\n\nIf a task have multiple metrics, each metric is first tranformed into points or ranks as illustrated above. Then, points or ranks are first averaged in intra-task fashion before being averaged with other task.\n\nTask|PR|SID|ER|ASR|QbE|ASV|SD|ST|SE|SE|SS\n-|-|-|-|-|-|-|-|-|-|-|-\nMetrics|PER|ACC|ACC|WER|MTWV|EER|DER|BLEU|PESQ|STOI|SS\nFBANK|82.01|41.38|48.24|23.18|0.58|9.56|10.05|2.32|2.55|0.9364|9.234\nSOTA|3.53|96.66|67.62|3.62|7.36|5.62|5.11|20.01|2.64|0.9418|10.45\n\n## Winner Minimum Requirements\n\nThe following describes the minimum requirements for a team to win the challenge.\n\n### Submit an upstream model to the hidden-set leaderboard\n\nThe public-set is for the upstream development purpose. You can pre-train your upstream and evaluate it with any method you like. You are required to submit at least one upstream model to the hidden-set leaderboard. The hidden-set leaderboard submission deadline is **Jan 10, 2022**.\n\n### Submission selection\n\nA team can **select at most 2 submissions** among its previous submissions for the final team ranking: one for the parameter-agnostic metrics and another for the parameter-panelized metrics. However, these 2 submissions **must come from the same method** and only differ in parameter size. The deadline for the submission selection is **Jan 13, 2022**.\n\n### System description paper\n\nTo verify the submitted upstream follows the challenge policy, we require each team to submit a system description paper in **AAAI submission format** without the page limit. The paper should describe the method **for the selected submissions**, containing at least the following materials:\n\n- SSL objectives\n- Model architecture\n- Pre-training data\n- Parameter size for each submission\n\nSince all the selected submissions come from the same method, the above materials should be almost identical between submissions except for the parameter size.\n\nThe submission should follow the challenge policy and the paper is expected to be well-written. The deadline for the system description paper is **Jan 13, 2022**.\n\n#### Note 1.\n\nThe system description paper is for the challenge review only and is not considered as our AAAI workshop paper by default, since the [AAAI workshop has the early hard deadlines](https://aaai.org/Conferences/AAAI-22/ws22call/) for both paper submission (**Nov 12, 2021**) and acceptance/rejection announcement (**Dec 3, 2021**). Hence, **we encourage participants to submit their methods\' papers early to our AAAI workshop** before Nov 12, 2021. If the method turns out to be similar to that used for the final selected submissions, the same paper can be used as the system description paper.\n\n#### Note 2.\n\nWe plan to work with other conferences and offer presentation & paper submission opportunities.\n\n## Winner Announcement and Presentation\n\nAfter review the system description papers and compare their performance with the hidden-set **private scores**. We will reveal all the private scores and announce the final winners on **January 20, 2022**. The winners will be invited to present their methods in our AAAI workshop.\n\n## Timeline\n\n- Sep 18, 2021: Challenge announcement & [S3PRL](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/docs/superb.md) released\n- Sep 30, 2021: [Overall metrics](challenge#Overall-Metrics) announcement & [public-set leaderboard](leaderboard?track=constrained&subset=Public+Set) is online and [accepts submissions](submit?type=public)\n- Oct 15, 2021: [Hidden-set leaderboard](leaderboard?track=constrained&subset=Hidden+Dev+Set) is online and [accepts submissions](submit?type=hidden)\n- Nov 12, 2021: [AAAI workshop](https://aaai-sas-2022.github.io/) paper submission deadline (encouraged)\n- Dec 3, 2021: [AAAI workshop](https://aaai-sas-2022.github.io/) paper acceptance / rejection announcement\n- Jan 10, 2022: Hidden-set leaderboard submission deadline\n- Jan 13, 2022: Submission selection & system description paper deadline\n- Jan 20, 2022: Winner announcement & reveal hidden-set private scores\n- Jan 22, 2022: AAAI late [registration](https://aaai.org/Conferences/AAAI-21/registration/) deadline\n- Feb 28 - Mar 1, 2022: [AAAI workshop](https://aaai-sas-2022.github.io/) presentation\n\n## Organizers\n\nHung-yi Lee\n\nShinji Watanabe\n\nAbdelrahman Mohamed\n\nShang-Wen Li\n\nShuyan Dong\n\nHeng-Jui Chang\n\nHsuan-Jui Chen\n\nPo-Han Chi\n\nXuankai Chang\n\nYung-Sung Chuang\n\nTzu-Hsun Feng\n\nTzu-Hsien Huang\n\nWen-Chin Huang\n\nZili Huang\n\nAndy T. Liu\n\nCheng-I Jeff Lai\n\nGuan-Ting Lin\n\nKushal Lakhotia\n\nYist Y. Lin\n\nYassin Omar\n\nJiatong Shi\n\nHsiang-Sheng Tsai\n\nLewis Tunstall\n\nWei-Cheng Tseng\n\nShu-wen Yang\n\n## Hidden-set Committee\n\nXuankai Chang\n\nHsuan-Jui Chen\n\nYung-Sung Chuang\n\nZili Huang\n\nShang-Wen Li\n\nGuan-Ting Lin\n\nYassin Omar\n\nJiatong Shi\n\nHsiang-Sheng Tsai\n\nShu-wen Yang\n\n# Contact\n\nsuperb.announcement@gmail.com\n'],['\n# SUPERB Challenge\n\n## Evaluation Framework\n\n### Background\n\n![](https://i.imgur.com/FDARwvz.png)\n*Fig 1.*\n\nSUPERB Challenge follows the similar evaluation framework introduced in [SUPERB Benchmark](https://arxiv.org/abs/2105.01051), which benchmarks the **generalizability** of Self-Supervised Learning (SSL) on speech. SSL models are termed **Upstream** and are evaluated with various **Downstream** tasks. The framework extract **multiple frozen hidden states** from a single upstream model and trains a learnable **weighted-sum** over the hidden states along with the downstream model task-by-task.\n\n### Overview\n\n![](https://i.imgur.com/BNr2gfE.png)\n*Fig 2.*\n\nFig 2. illustrates the evaluation framework of the challenge. The challenge evaluates SSL models\' generalizability on 10 tasks. Each of the tasks has a corresponding public dataset (**public-set**) that is publicly available, and a hidden dataset (**hidden-set**) that will not be released. Participants can practice on the public-set to understand the performance of their upstream models, and choose the best one for submission as they wish. Then, participants **submit the upstream model** (model definition & pre-trained weights) publicly or privately to the hidden-set leaderboard. **We finetune the downstream models on the hidden-set** without releasing any audio/label. Both public-set and hidden-set have leaderboards and welcome submissions to share more results with the community. **The winners of the challenge will be solely determined by the ranking on the hidden-set leaderboard.** Finally, there will be **overall metrics** for ranking all upstreams.\n\nAll the participants are encouraged to submit papers to [*AAAI workshop: The 2nd Self-supervised Learning for Audio and Speech Processing*](https://aaai-sas-2022.github.io/). The winners of the challenge will be invited to present their methods in the workshop. We plan to collaborate with more conferences for participants to present their works and papers.\n\n### Tasks\n\n10 evaluation tasks are included in this challenge:\n\n- **Content**\n    - Phoneme Recognition (PR)\n    - Automatic Speech Recognition (ASR)\n    - Query-by-example Spoken Term Detection (QbE)\n- **Speaker**\n    - Speaker Identification (SID)\n    - Automatic Speaker Verification (ASV)\n    - Speaker Diarization (SD)\n- **Paralinguistics**\n    - Emotion Recognition (ER)\n- **Semantics**\n    - Speech Translation (ST)\n- **Generation**\n    - Speech Enhancement (SE)\n    - Speech Separation (SS)\n\nMore task descriptions for the public-set can be found in [TASKS](https://superbbenchmark.org/tasks), and we implement the evaluation scripts for public-set in [S3PRL](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/docs/superb.md) for reference. The task design and evaluation pipeline will be the same between public-set & hidden-set unless otherwise mentioned.\n\n### Secret tasks\n\nSecret tasks evaluate SSL models\' generalizability on completely unseen tasks. Secret tasks are only present in the hidden-set, and the task design will not be revealed until the final winner announcement. \n\n### What is new\n\nCompared with SUPERB Benchmark, SUPERB Challenge extends the framework with the following:\n\n- **New Tasks**: Speech Translation, Speech Enhancement, Source Separation and secret tasks.\n- **New Data Domains**: A challenging and newly recorded hidden-set with unseen (to upstream) text/audio domain.\n- **New Overall Metrics**: The metrics to rank upstreams.\n\n\n## Upstream Specification\n\n### Unlabeled data only: Focus on SSL\n\n- Any labeled/parallel data made by human annotators are **not allowed** to used for both model training and data preprocessing, e.g.\n    - **audio/text pairs:** transcriptions in English, foreign languages, or phonemes.\n    - **audio/tagging pairs:** speaker labels or sound event labels.\n    - **audio/audio pairs:** audios with the same properties made parallel by human, e.g. audios with same content from different speakers, or the opposite.\n- Any system pre-trained by labeled/parallel data **cannot** be used to help with the SSL pre-training, like pre-trained ASR.\n- Any unlabeled/unparallel data is allowed, including the downstream datasets in the public-set. The nature alignments (not made by human annotators) bettwen audio and other modalities are also allowed, e.g. videos.\n- If it is hard to define whether your data is labeled/parallel, please [contact us](#Contact)!\n\n### Programming Language\n\n- We currently support:\n    - **Python >= 3.6**\n    - **Pytorch >= 1.7**\n\n- We expect the upstream submission can pass the following check:\n    ~~~python=\n    upstream = YourModel.cuda()\n    assert isinstance(upstream, torch.nn.Module)\n    ~~~\n\n\nWe accept upstream models in PyTorch by default. If you wish to submit upstreams in non-PyTorch frameworks, please [fill this form](https://docs.google.com/forms/d/e/1FAIpQLSe52jYL2Yk9oYqXfg_Bg0Sjp01a6HSLUhY5VohsZOE5sNmgsw/viewform)!\nIf you are not feasible to submit the pre-trained model, please [fill this form](https://docs.google.com/forms/d/e/1FAIpQLSdA44nArlIDfGV63WwtwXer4WAPQO1aBwEpAjDSNjbMQN-GJQ/viewform) for us to see how to help!\n\n### Interface functions\n\n#### forward\n\nExtract features from waveforms.\n\n- **Input:** A list of waveforms in 16000 Hz\n\n    ~~~python=\n    SAMPLE_RATE = 16000\n    BATCH_SIZE = 8\n    EXAMPLE_SEC = 10\n    wavs = [torch.randn(SAMPLE_RATE * EXAMPLE_SEC).cuda() for _ in range(BATCH_SIZE)]\n    results = upstream(wavs)\n    ~~~\n\n- **Output:** A dictionary with a key for each task, and a single key for all secret tasks. If any task-specific key is not presented, a "hidden_states" key should be provided as the default key. The value for each key is **a list** of padded sequences in the same shape of **(batch_size, max_sequence_length_of_batch, hidden_size)** for weighted-sum to work. It is welcomed to perform some preprocessing on the upstream\'s raw hidden-sets, including upsampling and downsampling. However, all the values must come from **a single upstream model**:\n\n    ~~~python=\n    assert isinstance(results, dict)\n    tasks = ["PR", "SID", "ER", "ASR", "ASV", "SD", "QbE", "ST", "SS", "SE", "secret"]\n    for task in tasks:\n        hidden_states = results.get(task, "hidden_states")\n        assert isinstance(hidden_states, list)\n\n        for state in hidden_states:\n            assert isinstance(state, torch.Tensor)\n            assert state.dim() == 3, "(batch_size, max_sequence_length_of_batch, hidden_size)"\n            assert state.shape == hidden_states[0].shape\n    ~~~\n\n#### get_downsample_rates\n\nProvide the downsample rate **from 16000 Hz waveforms** for each task\'s representation in the dict. For the standard 10ms stride representation, the downsample rate is 160.\n\n~~~python=\nSAMPLE_RATE = 16000\nMSEC_PER_SEC = 1000\ndownsample_rate = SAMPLE_RATE * 10 / MSEC_PER_SEC  # 160\n~~~\n\nThe downsample rate will be used to:\n\n1. Calculate the valid representation length of each utterance in the output padded representation.\n2. Prepare the training materials according to the representation\'s downsample rate for frame-level tasks: SD, SE, SS.\n\n- **Input:** the task key (str)\n- **Output:** the downsample rate (int) of the representation for that task\n\n~~~python=\nfor task in tasks:\n    assert isinstance(task, str)\n    downsample_rate = upstream.get_downsample_rate(task)\n    assert isinstance(downsample_rate, int)\n    print("The upstream\'s representation for {task}"\n        f" has the downsample rate of {downsample_rate}.")\n~~~\n\n## Public-set and S3PRL toolkit\n\n### As the task definition and demonstration\n\nThe public-set serves as the demonstration of the task design: including the data preprocessing, tasks\' input/output formats and task-specific metrics. The datasets used in the public-set are all chosen to be public available for everyone to participate. Please refer to [TASKS](https://superbbenchmark.org/tasks) and the implementation in [S3PRL](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/docs/superb.md) for details.\n\n### As the platform for developing upstreams for the hidden-set\n\nThe differences between the public-set and the hidden-set are controlled to be only the following:\n\n1. Recording conditions\n2. Spoken content / text scripts\n3. Speakers\n4. Fewer labeled data\n\nIn this way, the public-set is still a good indicator of the hidden-set performance to some degree. We follow the same (unless mentioned otherwise in [TASKS](/tasks)) implementation in the public-set for the hidden-set, and hence encourage participants to use [S3PRL](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/docs/superb.md) to benchmark their upstream models (optional) on the public-set. The winners of the challenge will be decided solely on the hidden-set, and the public-set and [S3PRL](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/docs/superb.md) implementations can serve as the start-kit.\n\n### Provide baselines for comparison\n\n#### Baselines\n\nWe collected most of the well-known SSL baseline models in [S3PRL](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/docs/superb.md), including TERA, wav2vec2, Hubert, DeCoAR 2.0, and more. You can easily benchmark different upstreams by specifying in the command line arguments.\n\n#### Comparison\n\nSince the full benchmarking on the public-set can take some time for the training to converge. We released the [training artifacts](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/docs/superb_artifacts.md) of the top baseline systems (e.g. wav2vec2, HuBERT) for participants to quickly compare with them. The artifacts include:\n\n- Tensorboard logs\n- Trained downstream weights (the best on public dev set)\n\n### Public-set leaderboard and submission\n\nThe [public-set leaderboard](leaderboard?subset=Public+Set&track=constrained) is online and [accepts submissions](submit?type=public). There is no deadline. Since all the train/dev/test splits are public available, **the leaderboard accepts submissions with the inferenced prediction files on each task\'s testing split** which will be auto-generated if you follow the benchmarking steps in [S3PRL](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/docs/superb.md).\n\n## Hidden-set\n\n### Fairness & prevent overfitting\n\nSince all the train/dev/test splits are public in the public-set, it is possible to cheat by directly reporting the best results on the testing split, and the results are thus overfit on the testing split. Hence, the hidden-set is collected and prepared to follow the same task design as that in the public-set but with the newly created data. All the splits will **NOT be released in both audio and labels**. The members involved in the hidden-set preparation should **NOT** participate the challenge. These members are listed in the **Hidden-set Committee** below.\n\n### Hidden-set leaderboard and submission\n\n#### Submission type\n\nThe leaderboard accepts **submissions with the upstream model solely**, including **model definition** and **pre-trained weights**. The upstream model should follow the specification detailed at [Upstream Specification](#Upstream-Specification). The submission can be done publicly or privately. Only the **Hidden-set Committee** members can access the privately submitted upstreams and the models will be used solely for this challenge.\n\n- We accept upstream models in PyTorch by default. If you wish to submit upstreams in non-PyTorch frameworks, please [fill this form](https://docs.google.com/forms/d/e/1FAIpQLSe52jYL2Yk9oYqXfg_Bg0Sjp01a6HSLUhY5VohsZOE5sNmgsw/viewform)!\n- If you are not feasible to submit the pre-trained model, please [fill this form](https://docs.google.com/forms/d/e/1FAIpQLSdA44nArlIDfGV63WwtwXer4WAPQO1aBwEpAjDSNjbMQN-GJQ/viewform) for us to see how to help!\n\n#### Finetuning on submission\n\nAfter the upstream model is submitted, we **benchmark the submitted upstream by finetuning each task\'s downstream model for participants**. **The quota for submissions per week is limited and starts from 2 times/week,** but will be dynamically adjusted based on the number of participants. The quota adjustment will be announced at [NEWS](https://superbbenchmark.org/news). Participants can [contact us](#Contact) to acquire the finetuning artifacts of their own submissions for sanity checks, including:\n\n- Tensorboard logs\n- Testing results\n- Trained downstream weights\n\n#### Practice (dev) / Private (test) scores\n\nAfter training the downstream model for all tasks, we show the best performance on the hidden-set\'s development splits as the **practice scores** (one score per task). The true performance on the testing splits, termed **private scores**, will be revealed along with the final winner announcement. The final team ranking will depend only on the hidden-set\'s **private scores**.\n\n#### How to submit\n\n(Update 10/20/2021 AOE)\n\nThe [hidden-set leaderboard](leaderboard?subset=Hidden+Dev+Set&track=constrained) is online and accepts submissions. Please follow [the submission steps](https://huggingface.co/superb/superb-submission). We use HuggingFace\'s Hub to host the submitted upstreams and track the submitted model weights. On the other hand, we use our [submission page](submit?type=hidden) to control the submission limit, where the participants tell us the locations of their models on HuggingFace\'s Hub.\n\nAfter submitting via the submission page, you will see a new entry in the **submission history** under your Profile page, and the evaluation results on the hidden-set will be revealed at the entry within one week.\nPlease stay tuned!\n\n(Update 10/31/2021 AOE)\n\nAll the submitted results will remain anonymous during and after the challenge.\nYou can select a few submissions to show on the leaderboard.\nIf no submission is selected, we will show all your submissions on the leaderboard anonymously.\nOnly you can see your personal/model information on the leaderboard, but you will not see others\'.\nIf you wish to reveal your personal/model information on the [hidden-set leaderboard](leaderboard?subset=Hidden+Dev+Set&track=constrained), please [contact us](#Contact)!\n\n## Overall Metrics\n\n(Update 10/1/2021 AOE)\n\nWe announce two kinds of metrics: **superb-rank** and **superb-score**, each with parameter-agnostic and parameter-panelized versions.\n\nType|Parameter-agnostic|Parameter-penalized\n-|-|-\nScoring|$superb_s$|$superb_{sp}$\nRanking|$superb_r$|$superb_{rp}$\n\nIn this challenge, $superb_r$ and $superb_{rp}$ are the primary metrics. When equal rank is found on two different upstreams, $superb_{s}$ or $superb_{sp}$ is used to break the tie. Hence, there will be only two final lists of winners: **Parameter-agnostic** and **Parameter-penalized**.\n\n### Notation\n\nSuppose each task $t$ in all tasks $T$ has a single metric $s_t$, and the score of an upstream $u$ on task $t$ is $s_t(u)$ which has already been transformed to make higher values represent better performance. Eg. We use WAcc here for ASR instead of the raw WER. The upstream $u$ has $|u|$ millions parameters.\n\n### Parameter-agnostic\n\nParameter-agnostic metrics demonstrate the best performance SSL can achieve, and encourages participants to explore any possibility to push the limits.\n\n#### $superb_s$\n\nTo aggregate all task-specific scores $s_t(u)$ into a single static score, we linearly transform each of them into points so that:\n\n- $s_t(fbank) = 0$, The performance of FBANK maps to 0\n- $s_t(sota) = 1000$, The performance of the existing SOTA upstream *for this task* maps to 1000.\n\n$$\np_t(u) = \\dfrac{1000}{s_t({sota}) - s_t({fbank})}\\ (\\ s_t(u) - s_t({fbank})\\ )\n$$\n\nHence, most of the points will sit between 0~1000. The upstream worse than FBANK on this task will get negative points. The upstream better than the task-specific SOTA upstream will get points higher than 1000. The $superb_s$ of the upstream $u$ is the average of $p_t$ over all tasks.\n\n$$\nsuperb_s = \\dfrac{1}{|T|} \\sum_{t \\in T}\\ p_t(u)\n$$\n\nIntuitively, two reference points: FBANK and SOTA decide the typical interested interval for a task-specific metric and scale the task scores to 0~1000 points accordingly. The similar range of points across tasks can then be averaged. Beyond scaling with the pre-defined metric range, this interval further determines *how hard for a task to improve*. For a harder task, its smaller interval at the denominator give the task more credit for any unit improvement.\n\n#### $superb_r$\n\nTo encourage the development on **universal models** instead of models skewed toward a subset of tasks. We use ranking to saturate the improvement when an upstream already become the best for that task. The $superb_r$ for an upstream $u$ is the average number of upstreams which $u$ can win in each task. This metric dynamically depends on all the upsreams $U$ shown on the leaderboard. In the following, $L$ is the number of upstreams which $u$ can win using the metric $x_t$.\n\n$$\nL(x_t, u) = |\\ \\{\\ \\hat{u} \\in U\\ |\\ x_t(u) > x_t(\\hat{u}) \\ \\}\\ |\n$$\n\n$$\nsuperb_r = \\dfrac{1}{|T|} \\sum_{t \\in T} L(s_t, u) = \\dfrac{1}{|T|} \\sum_{t \\in T} L(p_t, u)\n$$\n\n### Parameter-penalized\n\nTo encourage the development of speech SSL on small and green models, we add a metric with penalization on models\' parameter size. To gauge the effectiveness and parameter-efficiency of new SSL algorithms, we encourage participants to submit multiple upstreams trained by the same algorithm with the only difference in parameter size.\n\n#### $superb_{sp}$\n\nWe penalize the parameter-agnostic scoring by an upstream $u$\'s parameter size $|u|$.\n\n$$\n\\hat{p_t}(u) =\n\\left\\{\n    \\begin{array}{lr}\n        \\frac{p_t(u)}{\\ max(|u|,\\ 1)},& \\text{if } p_t(u) \\geq 0\\\\\n        \\ \\ \\ \\ p_t(u),              & \\text{otherwise}\n    \\end{array}\n\\right.\n$$\n\nSince either the point of the baseline FBANK or its parameter size is 0. The above formula measures how many improvement upon FBANK per parameter. The minimum 1 million parameter size is designed to avoid too small upstreams dominating others by receiving too much credit on a single task. When $p_t(u)$ is negative we do not penalize it, since it is already worse than the zero-parameter FBANK.\n\n$$\nsuperb_{sp} = \\dfrac{1}{|T|} \\sum_{t \\in T}\\ \\hat{p_t}(u)\n$$\n\n#### $superb_{sp}$\n\nSimilar to $superb_r$, we rank all upstreams on the leaderboard with $\\hat{p_t}$.\n\n$$\nsuperb_{rp} = \\dfrac{1}{|T|} \\sum_{t \\in T}\\ L(\\hat{p_t}, u)\n$$\n\n### Conclusion\n\nThe ranking metrics are the primary measures in this challenge and are designed to emphasize an upstream\'s universally usability. When two upstreams tie on the same rank, the scoring metrics take the tasks\' variations and improvement difficulty into account to help the final decision. You can refer to the [public-set leaderboard](leaderboard?subset=Public+Set&track=constrained) for the overal metrics calculation.\n\n#### Reference points\n\nIf a task have multiple metrics, each metric is first tranformed into points or ranks as illustrated above. Then, points or ranks are first averaged in intra-task fashion before being averaged with other task.\n\nTask|PR|SID|ER|ASR|QbE|ASV|SD|ST|SE|SE|SS\n-|-|-|-|-|-|-|-|-|-|-|-\nMetrics|PER|ACC|ACC|WER|MTWV|EER|DER|BLEU|PESQ|STOI|SS\nFBANK|82.01|41.38|48.24|23.18|0.58|9.56|10.05|2.32|2.55|0.9364|9.234\nSOTA|3.53|96.66|67.62|3.62|7.36|5.62|5.11|20.01|2.64|0.9418|10.45\n\n## Winner Minimum Requirements\n\nThe following describes the minimum requirements for a team to win the challenge.\n\n### Submit an upstream model to the hidden-set leaderboard\n\nThe public-set is for the upstream development purpose. You can pre-train your upstream and evaluate it with any method you like. You are required to submit at least one upstream model to the hidden-set leaderboard. The hidden-set leaderboard submission deadline is **Jan 10, 2022**.\n\n### Submission selection\n\nA team can **select at most 2 submissions** among its previous submissions for the final team ranking: one for the parameter-agnostic metrics and another for the parameter-panelized metrics. However, these 2 submissions **must come from the same method** and only differ in parameter size. The deadline for the submission selection is **Jan 13, 2022**.\n\n### System description paper\n\nTo verify the submitted upstream follows the challenge policy, we require each team to submit a system description paper in **AAAI submission format** without the page limit. The paper should describe the method **for the selected submissions**, containing at least the following materials:\n\n- SSL objectives\n- Model architecture\n- Pre-training data\n- Parameter size for each submission\n\nSince all the selected submissions come from the same method, the above materials should be almost identical between submissions except for the parameter size.\n\nThe submission should follow the challenge policy and the paper is expected to be well-written. The deadline for the system description paper is **Jan 13, 2022**.\n\n#### Note 1.\n\nThe system description paper is for the challenge review only and is not considered as our AAAI workshop paper by default, since the [AAAI workshop has the early hard deadlines](https://aaai.org/Conferences/AAAI-22/ws22call/) for both paper submission (**Nov 12, 2021**) and acceptance/rejection announcement (**Dec 3, 2021**). Hence, **we encourage participants to submit their methods\' papers early to our AAAI workshop** before Nov 12, 2021. If the method turns out to be similar to that used for the final selected submissions, the same paper can be used as the system description paper.\n\n#### Note 2.\n\nWe plan to work with other conferences and offer presentation & paper submission opportunities.\n\n## Winner Announcement and Presentation\n\nAfter review the system description papers and compare their performance with the hidden-set **private scores**. We will reveal all the private scores and announce the final winners on **January 20, 2022**. The winners will be invited to present their methods in our AAAI workshop.\n\n## Timeline\n\n- Sep 18, 2021: Challenge announcement & [S3PRL](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/docs/superb.md) released\n- Sep 30, 2021: [Overall metrics](challenge#Overall-Metrics) announcement & [public-set leaderboard](leaderboard?track=constrained&subset=Public+Set) is online and [accepts submissions](submit?type=public)\n- Oct 15, 2021: [Hidden-set leaderboard](leaderboard?track=constrained&subset=Hidden+Dev+Set) is online and [accepts submissions](submit?type=hidden)\n- Nov 12, 2021: [AAAI workshop](https://aaai-sas-2022.github.io/) paper submission deadline (encouraged)\n- Dec 3, 2021: [AAAI workshop](https://aaai-sas-2022.github.io/) paper acceptance / rejection announcement\n- Jan 10, 2022: Hidden-set leaderboard submission deadline\n- Jan 13, 2022: Submission selection & system description paper deadline\n- Jan 20, 2022: Winner announcement & reveal hidden-set private scores\n- Jan 22, 2022: AAAI late [registration](https://aaai.org/Conferences/AAAI-21/registration/) deadline\n- Feb 28 - Mar 1, 2022: [AAAI workshop](https://aaai-sas-2022.github.io/) presentation\n\n## Organizers\n\nHung-yi Lee\n\nShinji Watanabe\n\nAbdelrahman Mohamed\n\nShang-Wen Li\n\nShuyan Dong\n\nHeng-Jui Chang\n\nHsuan-Jui Chen\n\nPo-Han Chi\n\nXuankai Chang\n\nYung-Sung Chuang\n\nTzu-Hsun Feng\n\nTzu-Hsien Huang\n\nWen-Chin Huang\n\nZili Huang\n\nAndy T. Liu\n\nCheng-I Jeff Lai\n\nGuan-Ting Lin\n\nKushal Lakhotia\n\nYist Y. Lin\n\nYassin Omar\n\nJiatong Shi\n\nHsiang-Sheng Tsai\n\nLewis Tunstall\n\nWei-Cheng Tseng\n\nShu-wen Yang\n\n## Hidden-set Committee\n\nXuankai Chang\n\nHsuan-Jui Chen\n\nYung-Sung Chuang\n\nZili Huang\n\nShang-Wen Li\n\nGuan-Ting Lin\n\nYassin Omar\n\nJiatong Shi\n\nHsiang-Sheng Tsai\n\nShu-wen Yang\n\n# Contact\n\nsuperb.announcement@gmail.com\n'])));Object(d.a)((function(e){return{image:{width:"400",height:"500",marginBottom:e.spacing(2)}}}));var Zt=function(e){var t=Object(g.a)();return Object(x.jsx)(S,{children:Object(x.jsx)(S,{margin:t.spacing(8,"auto",1),align:"left",children:Object(x.jsx)(Vt.a,{children:Xt,remarkPlugins:[Yt.a,Jt.a],rehypePlugins:[Qt.a],components:{code:function(e){e.node;var t=e.inline,n=e.className,a=e.children,i=Object(O.a)(e,["node","inline","className","children"]),r=/language-(\w+)/.exec(n||"");return!t&&r?Object(x.jsx)(Kt.a,Object(f.a)({children:String(a).replace(/\n$/,""),language:r[1],PreTag:"div",style:Gt.a,showLineNumbers:!0},i)):Object(x.jsx)("code",Object(f.a)(Object(f.a)({className:n},i),{},{children:a}))},a:function(e){var t=e.href,n=e.children,a=Object(O.a)(e,["href","children"]),i=/.*superbbenchmark\.org\/\w+/.exec(t||"");return i?Object(x.jsx)(R.a,Object(f.a)(Object(f.a)({to:i[0].replace(/.*superbbenchmark\.org/,"")+"#top"},a),{},{children:n})):Object(x.jsx)("a",Object(f.a)(Object(f.a)({href:t},a),{},{children:n}))},h1:function(e){e.level;var t=e.children,n=(Object(O.a)(e,["level","children"]),t.toString().replace(/ /g,"-"));return Object(x.jsx)("h1",{id:n,children:t})},h2:function(e){e.level;var t=e.children,n=(Object(O.a)(e,["level","children"]),t.toString().replace(/ /g,"-"));return Object(x.jsx)("h2",{id:n,children:t})},h3:function(e){e.level;var t=e.children,n=(Object(O.a)(e,["level","children"]),t.toString().replace(/ /g,"-"));return Object(x.jsx)("h3",{id:n,children:t})},h4:function(e){e.level;var t=e.children,n=(Object(O.a)(e,["level","children"]),t.toString().replace(/ /g,"-"));return Object(x.jsx)("h4",{id:n,children:t})},h5:function(e){e.level;var t=e.children,n=(Object(O.a)(e,["level","children"]),t.toString().replace(/ /g,"-"));return Object(x.jsx)("h5",{id:n,children:t})}}})})})},en=n(861),tn=n(860),nn=n(862),an=n(863),rn=n(864),sn=n(865),on=n(867),cn=n(342),ln=n.n(cn),dn=n(878),hn=n(866),un=n(12),pn=n(8),mn=n(877),bn=n(847),gn=n(788),jn=n(859),fn=Object(d.a)({list:{width:200,paddingLeft:20,paddingRight:20},fullList:{width:"auto"}});function On(e){var t=fn(),n=i.a.useState({top:!1,left:!1,bottom:!1,right:!1}),a=Object(o.a)(n,2),r=a[0],s=a[1],c=function(e,t){return function(n){(!n||"keydown"!==n.type||"Tab"!==n.key&&"Shift"!==n.key)&&s(Object(f.a)(Object(f.a)({},r),{},Object(un.a)({},e,t)))}},l=function(n){return Object(x.jsx)("div",{className:Object(pn.a)(t.list,Object(un.a)({},t.fullList,"top"===n||"bottom"===n)),role:"presentation",onClick:c(n,!1),onKeyDown:c(n,!1),children:Object(x.jsx)(bn.a,{children:e.items.map((function(e){var t=Object(o.a)(e,2),n=t[0],a=t[1];return Object(x.jsxs)("div",{children:[Object(x.jsx)(E,{link:a,children:Object(x.jsx)(gn.a,{button:!0,children:Object(x.jsx)(jn.a,{children:n})})}),Object(x.jsx)(A.a,{})]})}))})})};return Object(x.jsx)("div",{children:["right"].map((function(t){return Object(x.jsxs)(i.a.Fragment,{children:[Object(x.jsx)("div",{onClick:c(t,!0),children:e.children}),Object(x.jsx)(mn.a,{anchor:t,open:r[t],onClose:c(t,!1),onOpen:c(t,!0),children:l(t)})]},t)}))})}function wn(e){var t=e.children,n=e.window,a=Object(en.a)({target:n?n():void 0});return Object(x.jsx)(tn.a,{appear:!1,direction:"down",in:!a,children:t})}function xn(e){var t=e.children,n=e.window,a=vn(),i=Object(c.f)(),r=Object(c.g)(),s=Object(en.a)({target:n?n():void 0,disableHysteresis:!0,threshold:100});return Object(x.jsx)(nn.a,{in:s,children:Object(x.jsx)("div",{onClick:function(e){var t=(e.target.ownerDocument||document).querySelector("#back-to-top-anchor");t&&(t.scrollIntoView({block:"center"}),i.push(r.pathname))},role:"presentation",className:a.root,children:t})})}var vn=Object(d.a)((function(e){return{root:{position:"fixed",bottom:e.spacing(2),right:e.spacing(2)},toolbar:{width:"100%",maxWidth:1600,margin:"auto",paddingLeft:20,paddingRight:20},tool:{paddingTop:5,paddingBottom:5},button:{paddingLeft:12,paddingRight:12,marginLeft:2,marginRight:2,borderRadius:10,border:"solid 1px transparent","&:hover":{background:"rgba(255, 255, 255, 1)",boxShadow:"0px 3px 10px rgba(0, 0, 0, 0.1)"},cursor:"pointer"},navlink:{fontWeight:"inherit"}}}));function Sn(e){var t=vn();return Object(x.jsx)("div",{className:"".concat(t.tool," ").concat(t.button),children:e.children})}var yn=Object(hn.a)()((function(e){e.width;var t=e.tableControlRef,n=Object(O.a)(e,["width","tableControlRef"]),r=vn(),s=Object(g.a)(),l=Object(c.g)(),d=[["News","/news"],["Paper","https://arxiv.org/abs/2105.01051"],["Code","https://github.com/s3prl/s3prl"],["Tasks","/tasks"],["Rules","/rules"],["Leaderboard","/leaderboard"],["Challenge","/challenge"],["Submit","/submit"]];return Object(a.useContext)(Ye).isLoggedIn?(d.push(["Profile","/profile"]),d.push(["Logout","/logout"])):d.push(["Login","/login"]),d=d.map((function(e){var t=Object(o.a)(e,2),n=t[0],a=t[1];return[Object(x.jsx)(m.a,{color:"textSecondary",variant:"overline",className:r.navlink,children:n},n),a]})),Object(j.a)(s.breakpoints.up("lg")),Object(x.jsxs)(i.a.Fragment,{children:[Object(x.jsx)(an.a,{}),Object(x.jsx)(wn,Object(f.a)(Object(f.a)({},n),{},{children:Object(x.jsx)(rn.a,{color:"primary",children:Object(x.jsx)(sn.a,{className:r.toolbar,children:Object(x.jsxs)(b.a,{container:!0,alignItems:"center",children:[Object(x.jsx)(b.a,{item:!0,xs:9,lg:2,children:Object(x.jsxs)(b.a,{container:!0,direction:"row",justify:"flex-start",alignItems:"center",spacing:1,children:[Object(x.jsx)(b.a,{item:!0,children:Object(x.jsx)(E,{link:"/",children:Object(x.jsx)(Sn,{children:Object(x.jsx)(m.a,{color:"textPrimary",variant:"h6",className:"".concat(r.navlink),children:"SUPERB"})})})}),(l.pathname.includes("leaderboard")||l.pathname.includes("profile"))&&Object(x.jsx)(b.a,{item:!0,children:Object(x.jsx)(E,{link:null,children:Object(x.jsx)(T.a,{size:"small",variant:"outlined",onClick:function(){t.current.click()},children:"Help"})})})]})}),Object(x.jsx)(b.a,{item:!0,xs:3,lg:10,children:Object(x.jsxs)(b.a,{container:!0,direction:"row",justify:"flex-end",alignItems:"center",children:[Object(x.jsx)(dn.a,{mdDown:!0,children:d.map((function(e){var t=Object(o.a)(e,2),n=t[0],a=t[1];return Object(x.jsx)(b.a,{item:!0,children:Object(x.jsx)(E,{link:a,children:Object(x.jsx)(Sn,{children:n})})},a)}))}),Object(x.jsx)(dn.a,{lgUp:!0,children:Object(x.jsx)(b.a,{item:!0,children:Object(x.jsx)(On,{items:d,children:Object(x.jsx)(Sn,{children:Object(x.jsx)(m.a,{color:"textSecondary",variant:"overline",children:"MENU"})})})})})]})})]})})})})),Object(x.jsx)(sn.a,{id:"back-to-top-anchor"}),Object(x.jsx)(xn,Object(f.a)(Object(f.a)({},n),{},{children:Object(x.jsx)(on.a,{color:"secondary",size:"small","aria-label":"scroll back to top",children:Object(x.jsx)(ln.a,{})})}))]})})),kn=n(198),_n=function(){var e=Object(a.useContext)(Ye),t=Object(c.f)(),n=function(){var n=Object(ze.a)(De.a.mark((function n(a){var i;return De.a.wrap((function(n){for(;;)switch(n.prev=n.next){case 0:return n.prev=0,n.next=3,Me.a.post("/api/user/login",{id_token:a.tokenId});case 3:i=n.sent,e.login(i.data.access_token,null,i.data.isAdmin,i.data.email),t.push("/"),n.next=11;break;case 8:n.prev=8,n.t0=n.catch(0),console.log(n.t0.response);case 11:case"end":return n.stop()}}),n,null,[[0,8]])})));return function(e){return n.apply(this,arguments)}}();return Object(x.jsx)(kn.GoogleLogin,{onSuccess:n,clientId:"796679159105-6335p2q2ub5pr15lnf3g2cqkhnucmvkl.apps.googleusercontent.com",buttonText:"Sign in with Google",theme:"dark",responseType:"id_token",isSignedIn:!0,uxMode:"redirect"})};function Tn(){var e=Object(a.useContext)(Ye);return Object(a.useEffect)((function(){e.logout()})),Object(x.jsx)(x.Fragment,{})}var An,Rn=n(344),Pn=n.n(Rn),En=n(343),Cn=n.n(En),Bn=n(846),Nn=n(843),Ln=n(870),$n=n(868),In=xt.a.div(An||(An=Object(wt.a)(["\n  .table {\n    outline: 1px solid #ddd;\n\n    .click-btn {\n      cursor: pointer;\n    }\n    \n    .th,\n    .td {\n      background-color: ",";\n      overflow: hidden;\n      white-space: nowrap;\n      text-overflow: ellipsis;\n      border: 0.2px solid #ddd;\n      vertical-align: middle;\n      padding: ",";\n    }\n\n    .th {\n      font-weight: bold;\n      padding: ",";\n    }\n\n    .toggle {\n      display: flex;\n      align-items: center;\n      justify-content: center;\n    }\n\n    &.sticky {\n      overflow: scroll;\n      .header,\n      .footer {\n        position: sticky;\n        z-index: 1;\n        width: fit-content;\n      }\n\n      .header {\n        top: 0;\n        box-shadow: 0px 3px 3px #ccc;\n      }\n\n      .footer {\n        bottom: 0;\n        box-shadow: 0px -3px 3px #ccc;\n      }\n\n      .body {\n        position: relative;\n        z-index: 0;\n      }\n\n      [data-sticky-td] {\n        position: sticky;\n      }\n\n      [data-sticky-last-left-td] {\n        box-shadow: 2px 2px 3px #ccc;\n      }\n\n      [data-sticky-first-right-td] {\n        box-shadow: -2px -2px 3px #ccc;\n      }\n    }\n  }\n\n  .resizer {\n    display: inline-block;\n    background: ",";\n    width: ",";\n    height: 100%;\n    position: absolute;\n    right: 0;\n    top: 0;\n    transform: translateX(50%);\n    z-index: 1;\n    ","\n    touch-action:none;\n\n    &.isResizing, &:hover {\n      background: ",";\n    }\n"])),(function(e){return e.theme.palette.primary.main}),(function(e){return e.theme.spacing(1,1)}),(function(e){return e.theme.spacing(1.5,1)}),(function(e){return"".concat(Object(_.b)(e.theme.palette.text.primary,.2))}),(function(e){return"".concat(e.theme.spacing(2),"px")}),"",(function(e){return"".concat(Object(_.b)(e.theme.palette.text.primary,.6))}));function Dn(e){var t=e.columns,n=e.data,a=e.height,r=void 0===a?"500px":a,s=e.tableControlRef,o=void 0===s?null:s,c=Object(g.a)(),l=i.a.useMemo((function(){return{minWidth:10,width:150,maxWidth:400}}),[]),d=i.a.useMemo((function(){return[{id:"aoeTimeUpload",desc:!0}]})),h=Object(vt.useTable)({columns:t,data:n,defaultColumn:l,initialState:{hiddenColumns:["modelURL","stride","inputFormat","corpus","paramDesc","paramShared","fineTunedParam","taskSpecParam","stateInfo","submitUUID"],sortBy:d}},vt.useSortBy,vt.useBlockLayout,vt.useResizeColumns,St.useSticky),u=h.getTableProps,p=h.getTableBodyProps,m=h.headerGroups,b=h.rows,j=h.prepareRow;return Object(x.jsxs)(In,{theme:c,children:[Object(x.jsx)(Lt,{tableInstance:h,modalOpenRef:o}),Object(x.jsxs)("div",Object(f.a)(Object(f.a)({},u()),{},{className:"table sticky",style:{width:"fit-content",maxWidth:"100%",maxHeight:r,margin:"auto"},children:[Object(x.jsx)("div",{className:"header",children:m.map((function(e){return Object(x.jsx)("div",Object(f.a)(Object(f.a)({},e.getHeaderGroupProps()),{},{className:"tr",children:e.headers.map((function(e){var t=void 0==e.isSortedDesc||void 0==e.higherBetter?c.palette.text.primary:e.isSortedDesc==e.higherBetter?J.a[300]:Y.a[300];return Object(x.jsxs)("div",Object(f.a)(Object(f.a)({},e.getHeaderProps()),{},{className:"th",children:[Object(x.jsxs)("div",Object(f.a)(Object(f.a)({},e.getSortByToggleProps()),{},{className:"toggle",children:[Object(x.jsx)("span",{style:{margin:"0px 1px",color:t},children:e.render("Header")}),void 0!=e.higherBetter&&(e.higherBetter?Object(x.jsx)(kt.a,{style:{fontSize:16,color:t}}):Object(x.jsx)(Tt.a,{style:{fontSize:16,color:t}}))]})),Object(x.jsx)("div",Object(f.a)(Object(f.a)({},e.getResizerProps()),{},{className:"resizer ".concat(e.isResizing?"isResizing":"")}))]}))}))}))}))}),Object(x.jsx)("div",Object(f.a)(Object(f.a)({},p()),{},{className:"body",children:b.map((function(e,t){return j(e),Object(x.jsx)("div",Object(f.a)(Object(f.a)({},e.getRowProps()),{},{className:"tr",children:e.cells.map((function(e){return Object(x.jsx)("div",Object(f.a)(Object(f.a)({},e.getCellProps()),{},{className:"td",children:e.render("Cell")}))}))}))}))}))]}))]})}var zn,Hn=function(e){var t=new URLSearchParams(Object(c.g)().search),n=Object(g.a)(),r=Object(a.useContext)(Ye),s=Object(a.useState)([]),l=Object(o.a)(s,2),d=l[0],h=l[1],u=Object(a.useState)([]),m=Object(o.a)(u,2),b=m[0],j=m[1],O=Object(a.useState)([]),w=Object(o.a)(O,2),v=w[0],y=w[1],k=Object(a.useState)([]),_=Object(o.a)(k,2),R=_[0],P=_[1],E=Object(a.useState)(t.get("track")||"constrained"),C=Object(o.a)(E,2),B=C[0],N=C[1],L=Object(a.useState)(""),$=Object(o.a)(L,2),z=$[0],H=$[1],F=Object(a.useState)(""),U=Object(o.a)(F,2),W=U[0],M=U[1],V=Object(a.useState)(0),Y=Object(o.a)(V,2),Q=Y[0],K=Y[1],G=Object(a.useState)(0),X=Object(o.a)(G,2),Z=X[0],ee=X[1],te=Object(a.useState)(0),ne=Object(o.a)(te,2),ae=ne[0],ie=ne[1],re=Object(a.useState)(0),se=Object(o.a)(re,2),oe=se[0],ce=se[1],le=Object(a.useState)(t.get("subset")||"Paper"),ue=Object(o.a)(le,2),pe=ue[0],me=ue[1],be=pe.toLowerCase().includes("hidden")?"hidden":"public",ge=i.a.useCallback(D),je=Object(a.useState)(""),fe=Object(o.a)(je,2),we=fe[0],xe=fe[1],ve=Object(a.useState)([]),Se=Object(o.a)(ve,2),ye=Se[0],ke=Se[1],_e=Object(a.useState)(!0),Te=Object(o.a)(_e,2),Ae=Te[0],Re=Te[1],Pe={CONSTRAINED:"constrained",LESS_CONSTRAINED:"less-constrained",UNCONSTRAINED:"unconstrained"},Ee=function(){var e=Object(ze.a)(De.a.mark((function e(){return De.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return e.next=2,Me()({method:"get",url:"/api/user/info",headers:{Authorization:"Bearer "+r.token}}).then((function(e){H(e.data.username),K(e.data.daily_counts),ee(e.data.weekly_counts),ie(e.data.hidden_daily_counts),ce(e.data.hidden_weekly_counts)})).catch((function(e){console.error(e)}));case 2:case"end":return e.stop()}}),e)})));return function(){return e.apply(this,arguments)}}(),Ce=function(){var e=Object(ze.a)(De.a.mark((function e(){return De.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return e.next=2,Me()({method:"patch",url:"/api/user/info",headers:{Authorization:"Bearer "+r.token},data:{name:W}}).then((function(e){H(e.data.newUserName),Ue()({text:"Reset to ".concat(e.data.newUserName,"!"),icon:"success"})})).catch((function(e){Ue()({text:"Internal server error",icon:"error"}),console.error(e)}));case 2:case"end":return e.stop()}}),e)})));return function(){return e.apply(this,arguments)}}(),Be=function(){var e=Object(ze.a)(De.a.mark((function e(){return De.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return e.next=2,Me()({method:"get",url:"/api/submissions",headers:{Authorization:"Bearer "+r.token}}).then((function(e){h(e.data.submission_info),y("all"===B?e.data.submission_info:e.data.submission_info.filter((function(e){return Pe[e.task]===B})))})).catch((function(e){console.error(e)}));case 2:return e.next=4,Me()({method:"get",url:"/api/hiddensubmissions",headers:{Authorization:"Bearer "+r.token}}).then((function(e){j(e.data.submission_info),P("all"===B?e.data.submission_info:e.data.submission_info.filter((function(e){return Pe[e.task]===B})))})).catch((function(e){console.error(e)}));case 4:if(!r.isAdmin){e.next=7;break}return e.next=7,Me()({method:"get",url:"/api/hiddensearch/",headers:{Authorization:"Bearer "+r.token}}).then((function(e){ke(e.data.submission_info)})).catch((function(e){console.error(e)}));case 7:case"end":return e.stop()}}),e)})));return function(){return e.apply(this,arguments)}}(),Ne=function(){var e=Object(ze.a)(De.a.mark((function e(t){return De.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return e.next=2,Me()({method:"patch",url:("hidden"==be?"/api/hiddensubmission/":"/api/submission/")+t,headers:{Authorization:"Bearer "+r.token}}).then((function(e){Ue()({text:e.data.message,icon:"success"}),Be()})).catch((function(e){Ue()({text:"Internal server error",icon:"error"})}));case 2:case"end":return e.stop()}}),e)})));return function(t){return e.apply(this,arguments)}}(),$e=function(e){var t=e.row;return"NO"===e.value?Object(x.jsx)(Cn.a,{className:"click-btn",onClick:function(){return Ne(t.original.submitUUID)}}):Object(x.jsx)(Pn.a,{className:"click-btn",style:{color:J.a[500]},onClick:function(){return Ne(t.original.submitUUID)}})},Ie=function(e){var t=e.row;return Object(x.jsx)(Rt.a,{className:"click-btn",onClick:function(){return He(t.allCells[16].value)}})},He=function(){var e=Object(ze.a)(De.a.mark((function e(t){return De.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return e.next=2,Me()({method:"get",url:"/api/submission/"+t,headers:{Authorization:"Bearer "+r.token},responseType:"blob"}).then((function(e){var t=new Blob([e.data],{type:"application.zip"}),n=document.createElement("a"),a=URL.createObjectURL(t);n.href=a,n.download="predict.zip",n.click()})).catch((function(e){Ue()({text:"Internal server error",icon:"error"})}));case 2:case"end":return e.stop()}}),e)})));return function(t){return e.apply(this,arguments)}}(),Fe=function(e){var t=e.value;return"-"===t?String(t):Object(x.jsx)("a",{href:t,children:Object(x.jsx)(Rt.a,{style:{height:"20px"}})})};Object(a.useEffect)((function(){Be(),Ee()}),[r.isAdmin]);var We=function(){var e=Object(ze.a)(De.a.mark((function e(){var t,n;return De.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:if(!r.isAdmin){e.next=5;break}return t=document.getElementById("submission-id").value,n=document.getElementById("edit-value").value,e.next=5,Me()({method:"patch",url:"/api/hiddenmodify/".concat(t,"&").concat(we,"&").concat(n),headers:{Authorization:"Bearer "+r.token}}).then((function(e){Ue()({text:e.data.message,icon:"success"}),Be()})).catch((function(e){Ue()({text:"Internal server error",icon:"error"})}));case 5:case"end":return e.stop()}}),e)})));return function(){return e.apply(this,arguments)}}(),Ve="hidden"==be?he:de,Qe=Object.keys(Ve).map((function(e){var t=Ve[e].isScore;return{Header:Ve[e].header,accessor:e,width:Ve[e].width,sortType:"number"==Ve[e]?ge:"alphanumeric",higherBetter:Ve[e].higherBetter,isScore:t,Cell:"showOnLeaderboard"===e?$e:"modelURL"===e?Fe:"download"===e&&"public"===be?Ie:function(e){var n=e.value;return t?I(n)?String(Math.round(100*n)/100):"-":void 0==n?"-":String(n)}}}));Qe[0].sticky="left";var Je,Ke,Ge=Ft(["interpolation","interpolation_p"],Qe,"hidden"==be?Ae&&r.isAdmin?ye:R:v,pe,ge),Ze=Object(o.a)(Ge,2);Je=Ze[0],Ke=Ze[1];var et=i.a.useMemo((function(){return Je}));return Object(x.jsxs)(x.Fragment,{children:[Object(x.jsxs)(S,{anchorKey:"personal-profile",margin:n.spacing(8,"auto",1),children:[Object(x.jsx)(Oe,{title:"Hello "+z,description:Object(x.jsxs)("div",{children:[Object(x.jsxs)("p",{children:[Object(x.jsx)("span",{children:"Public submissions: "}),Object(x.jsx)("strong",{children:"".concat(Q,"/day, ").concat(Z,"/week")})]}),Object(x.jsxs)("p",{children:[Object(x.jsx)("span",{children:"Hidden submissions: "}),Object(x.jsx)("strong",{children:"".concat(ae,"/day, ").concat(oe,"/week")})]})]})}),Object(x.jsx)(Xe.a,{required:!0,label:"Reset your name",id:"name-reset",defaultValue:z,size:"small",color:"secondary",onChange:function(e){M(e.target.value)}}),Object(x.jsx)(T.a,{variant:"contained",size:"small",className:"reset-name-btn",style:{margin:10},onClick:Ce,children:"Reset"})]}),Object(x.jsxs)(S,{anchorKey:"personal-submission",children:[Object(x.jsx)(Oe,{title:"Submission history",description:"You can check the checkbox to show your submission result(s) on the leaderboard."}),Object(x.jsxs)(p.a,{width:"90%",margin:"auto",children:[r.isAdmin&&Object(x.jsxs)(x.Fragment,{children:[Object(x.jsx)(Le.a,{control:Object(x.jsx)(Bt.a,{checked:Ae,onChange:function(e){Re(e.target.checked)},name:"showAll"}),label:"All Submissions"}),Object(x.jsx)(A.a,{style:{width:"600px",maxWidth:"80%",margin:"auto"}})]}),Object(x.jsx)(p.a,{margin:n.spacing(2,"auto",.2),children:Object(x.jsx)($t,{task:B,onTaskChange:function(e){N(e.target.value);var t=new URL(window.location);t.searchParams.set("track",e.target.value),window.history.pushState({},"",t);var n="hidden"===be?P:y,a="hidden"===be?b:d;"all"===e.target.value?n(a):n(a.filter((function(t){return Pe[t.task]===e.target.value})))}})}),Object(x.jsx)(A.a,{style:{width:"600px",maxWidth:"80%",margin:"auto"}}),Object(x.jsx)(p.a,{margin:n.spacing(.2,"auto",1),children:Object(x.jsx)(It,{subset:pe,selections:["Paper","Public Set","Hidden Dev Set"],onChange:function(e){me(e.target.value);var t=new URL(window.location);t.searchParams.set("subset",e.target.value),window.history.pushState({},"",t)}})})]}),Object(x.jsx)(Dn,Object(f.a)({columns:et,data:Ke},e)),r.isAdmin&&Object(x.jsxs)(S,{children:[Object(x.jsxs)(p.a,{margin:"10px",children:[Object(x.jsx)(Oe,{title:"Edit Hidden Score",description:"Great power comes with great responsibility."}),Object(x.jsxs)(qe.a,{style:{margin:"10px"},children:[Object(x.jsx)(Bn.a,{style:{color:q.a[600]},htmlFor:"submission-id",children:"Submission ID"}),Object(x.jsx)(Nn.a,{id:"submission-id"})]}),Object(x.jsxs)(qe.a,{style:{width:"200px",margin:"10px"},children:[Object(x.jsx)(Bn.a,{id:"demo-customized-select-label",children:"Task"}),Object(x.jsx)(Ln.a,{labelId:"demo-customized-select-label",id:"demo-customized-select",value:we,onChange:function(e){xe(e.target.value)},children:Object.keys(he).map((function(e){return he[e].isScore&&Object(x.jsx)($n.a,{value:e,children:e})}))})]}),Object(x.jsxs)(qe.a,{style:{margin:"10px"},children:[Object(x.jsx)(Bn.a,{style:{color:q.a[600]},htmlFor:"edit-value",children:"Edit Value"}),Object(x.jsx)(Nn.a,{id:"edit-value"})]})]}),Object(x.jsx)(T.a,{color:"primary",variant:"contained",onClick:We,children:"Edit"})]})]})]})},Fn=Object(d.a)((function(e){return{narrowViewport:{width:"85%",maxWidth:900,margin:"auto"},LoginButton:{height:"30vh",paddingTop:"10vh"}}}));function Un(){var e=i.a.useState(0),t=Object(o.a)(e,2),n=(t[0],t[1]),r=i.a.useState(0),s=Object(o.a)(r,2),d=s[0],h=s[1],u=i.a.useState(0),p=Object(o.a)(u,2),m=p[0],b=p[1],g=i.a.useRef(null),j=Object(a.useContext)(Ye),f=function(){n(window.innerWidth),h(window.innerHeight),b(document.getElementById("navbar").offsetHeight)};i.a.useEffect(f),window.addEventListener("resize",f);var O,w=Fn();return O=j.isLoggedIn?Object(x.jsxs)(c.c,{children:[Object(x.jsx)(c.a,{path:"/",exact:!0,children:Object(x.jsx)("div",{className:"".concat(w.narrowViewport),children:Object(x.jsx)(xe,{})})}),Object(x.jsx)(c.a,{path:"/news",children:Object(x.jsx)("div",{className:"".concat(w.narrowViewport),children:Object(x.jsx)(ke,{})})}),Object(x.jsx)(c.a,{path:"/tasks",children:Object(x.jsx)("div",{className:"".concat(w.narrowViewport),children:Object(x.jsx)(Re,{})})}),Object(x.jsx)(c.a,{path:"/rules",children:Object(x.jsx)("div",{className:"".concat(w.narrowViewport),children:Object(x.jsx)(ct,{})})}),Object(x.jsx)(c.a,{path:"/compare",children:Object(x.jsx)("div",{className:"".concat(w.narrowViewport),children:Object(x.jsx)(gt,{})})}),Object(x.jsx)(c.a,{path:"/leaderboard",children:Object(x.jsx)(qt,{height:"".concat(d-m,"px"),tableControlRef:g})}),Object(x.jsx)(c.a,{path:"/challenge",children:Object(x.jsx)("div",{className:"".concat(w.narrowViewport),children:Object(x.jsx)(Zt,{})})}),Object(x.jsx)(c.a,{path:"/profile",exact:!0,children:Object(x.jsx)(Hn,{tableControlRef:g})}),Object(x.jsx)(c.a,{path:"/logout",children:Object(x.jsx)(Tn,{})}),Object(x.jsx)(c.a,{path:"/submit",children:Object(x.jsx)("div",{className:"".concat(w.narrowViewport),children:Object(x.jsx)(st,{login:!0})})})]}):Object(x.jsxs)(c.c,{children:[Object(x.jsx)(c.a,{path:"/",exact:!0,children:Object(x.jsx)("div",{className:"".concat(w.narrowViewport),children:Object(x.jsx)(xe,{})})}),Object(x.jsx)(c.a,{path:"/news",children:Object(x.jsx)("div",{className:"".concat(w.narrowViewport),children:Object(x.jsx)(ke,{})})}),Object(x.jsx)(c.a,{path:"/tasks",children:Object(x.jsx)("div",{className:"".concat(w.narrowViewport),children:Object(x.jsx)(Re,{})})}),Object(x.jsx)(c.a,{path:"/rules",children:Object(x.jsx)("div",{className:"".concat(w.narrowViewport),children:Object(x.jsx)(ct,{})})}),Object(x.jsx)(c.a,{path:"/leaderboard",children:Object(x.jsx)(qt,{height:"".concat(d-m,"px"),tableControlRef:g})}),Object(x.jsx)(c.a,{path:"/challenge",children:Object(x.jsx)("div",{className:"".concat(w.narrowViewport),children:Object(x.jsx)(Zt,{})})}),Object(x.jsx)(c.a,{path:"/submit",children:Object(x.jsx)("div",{className:"".concat(w.narrowViewport),children:Object(x.jsx)(st,{login:!1})})}),Object(x.jsx)(c.a,{path:"/login",children:Object(x.jsx)("div",{className:"".concat(w.narrowViewport," ").concat(w.LoginButton),children:Object(x.jsx)(_n,{})})})]}),Object(x.jsx)("div",{className:"App",children:Object(x.jsxs)(l.a,{children:[Object(x.jsx)("div",{id:"navbar",children:Object(x.jsx)(yn,{tableControlRef:g})}),O]})})}var Wn=function(){var e=function(){var e=Object(a.useState)(!1),t=Object(o.a)(e,2),n=t[0],i=t[1],r=Object(a.useState)(!1),s=Object(o.a)(r,2),c=s[0],l=s[1],d=Object(a.useState)(null),h=Object(o.a)(d,2),u=h[0],p=h[1],m=Object(a.useState)(),b=Object(o.a)(m,2),g=b[0],j=b[1],f=Object(kn.useGoogleLogout)({clientId:"796679159105-6335p2q2ub5pr15lnf3g2cqkhnucmvkl.apps.googleusercontent.com",onLogoutSuccess:function(){},onFailure:function(){}}).signOut,O=Object(a.useCallback)((function(e,t,n,a){var r=t||new Date((new Date).getTime()+36e5);n=n||!1,a=a||null,i(e),j(r),l(n),p(a),localStorage.setItem("data",JSON.stringify({token:e,expiration:r.toISOString(),isAdmin:n,email:a}))}),[]),w=Object(a.useCallback)((function(){f(),i(null),j(null),l(!1),p(null),localStorage.removeItem("data")}),[]);return Object(a.useEffect)((function(){if(n&&g){var e=g.getTime()-(new Date).getTime();zn=setTimeout(w,e)}else clearTimeout(zn)}),[n,w,g]),Object(a.useEffect)((function(){var e=JSON.parse(localStorage.getItem("data"));e&&e.token&&new Date(e.expiration)>new Date&&e.email?O(e.token,new Date(e.expiration),e.isAdmin,e.email):w()}),[O]),{token:n,isAdmin:c,email:u,login:O,logout:w}}(),t=e.token,n=e.isAdmin,i=e.email,r=e.login,s=e.logout;return Object(x.jsx)(h.a,{theme:Object(u.a)(X),children:Object(x.jsx)(Ye.Provider,{value:{isLoggedIn:!!t,token:t,isAdmin:n,email:i,login:r,logout:s},children:Object(x.jsx)(Un,{})})})},Mn=function(e){e&&e instanceof Function&&n.e(3).then(n.bind(null,883)).then((function(t){var n=t.getCLS,a=t.getFID,i=t.getFCP,r=t.getLCP,s=t.getTTFB;n(e),a(e),i(e),r(e),s(e)}))};s.a.render(Object(x.jsx)(i.a.StrictMode,{children:Object(x.jsx)(Wn,{})}),document.getElementById("root")),Mn()}},[[780,1,2]]]);
//# sourceMappingURL=main.1ba5e0ac.chunk.js.map